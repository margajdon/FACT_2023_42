{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tables for FairCal based on Salvador et al., 2022\n",
    "## Reproduced by Group 42 of FACT-AI 2022/23 @ UvA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tables Reproduced\n",
    "\n",
    "1. Fairness Calibration\n",
    "2. Global Accuracy\n",
    "3. Predictive Equality ('fpr at fpr')\n",
    "4. Equal Opportunity ('fnr at fnr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.precision\", 2)\n",
    "import seaborn as sns\n",
    "import sklearn.metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fairness Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_approaches = {\n",
    "    'baseline':'Naive',\n",
    "    # 'fsn':'Fair Score',\n",
    "    'faircal':'FairCal (Ours)',\n",
    "    # 'oracle':'Oracle (Ours)'\n",
    "    }\n",
    "title_calibration_methods = {\n",
    "    'beta': 'Beta Calibration'\n",
    "}\n",
    "title_features = {\n",
    "    'facenet':'FaceNet (VGGFace2)',\n",
    "    'facenet-webface':'FaceNet (Webface)',\n",
    "    'arcface': 'ArcFace'}\n",
    "title_metrics = {\n",
    "    'mean': 'Mean',\n",
    "    'aad': 'AAD',\n",
    "    'mad': 'MAD',\n",
    "    'std': 'STD'}\n",
    "caption_metrics = {\n",
    "     'mean': 'Mean',\n",
    "     'aad': 'AAD (Average Absolute Deviation)',\n",
    "     'mad': 'MAD (Maximum Absolute Deviation)',\n",
    "     'std': 'STD (Standard Deviation)',\n",
    "}\n",
    "title_keys = {\n",
    "    'baseline': 'Baseline',\n",
    "    # 'agenda': 'AGENDA',\n",
    "    # 'ftc': 'FTC',\n",
    "    # 'fsn': 'FSN',\n",
    "    'faircal': 'FairCal (Ours)',\n",
    "    # 'oracle': 'Oracle (Ours)'\n",
    "    }\n",
    "header_titles = {\n",
    "    'African': 'Af',\n",
    "    'Asian': 'As',\n",
    "    'Caucasian': 'Ca',\n",
    "    'Indian': 'In',\n",
    "    'asian_females': 'AsF',\n",
    "    'asian_males': 'AsM',\n",
    "    'black_females': 'AfF',\n",
    "    'black_males': 'AfM',\n",
    "    'indian_females': 'IF',\n",
    "    'indian_males': 'IM',\n",
    "    'white_females': 'CF',\n",
    "    'white_males': 'CM',\n",
    "    'Global': 'Gl',\n",
    "    'B': 'Af',\n",
    "    'A': 'As',\n",
    "    'W': 'C',\n",
    "    'I': 'I',\n",
    "    'F': 'F',\n",
    "    'M': 'M'\n",
    "}\n",
    "title_datasets = {\n",
    "    'rfw': 'RFW',\n",
    "    'bfw': 'BFW'\n",
    "}\n",
    "caption_calibration_methods = {\n",
    "    'beta': 'beta calibration'\n",
    "}\n",
    "caption_measures = {\n",
    "    'ks': 'KS'\n",
    "}\n",
    "features_datasets = {\n",
    "    'rfw': ['facenet', 'facenet-webface'],\n",
    "    'bfw': ['facenet-webface']\n",
    "}\n",
    "attributes_datasets = {\n",
    "    'rfw': 'ethnicity',\n",
    "    'bfw': 'att',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_measures(dataset, feature, approach, subgroups, att, measure, calibration_method, nbins, n_clusters):\n",
    "    filename = f'../experiments/{dataset}/{feature}/{approach}/{calibration_method}/nbins_{nbins}'\n",
    "    if approach == 'faircal':\n",
    "        filename += f'_nclusters_{n_clusters}'\n",
    "    if approach == 'fsn':\n",
    "        filename += f'_nclusters_{n_clusters}_fpr_1e-03'\n",
    "\n",
    "    results = np.load(f'{filename}.npy', allow_pickle=True).item()\n",
    "\n",
    "    data = pd.DataFrame()\n",
    "    data['folds'] = ['fold1', 'fold2', 'fold3', 'fold4', 'fold5']\n",
    "    data = data.set_index('folds')\n",
    "    for fold in range(1, 6):\n",
    "        for j, subgroup in enumerate(subgroups[att]):\n",
    "            data.loc[f'fold{str(fold)}', f'{subgroup}'] = results[f'fold{str(fold)}'][measure][att][subgroup]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              B     A     W         I\n",
      "folds                                \n",
      "fold1  9.21e-03  0.01  0.02  1.64e-02\n",
      "fold2  2.28e-02  0.03  0.02  2.35e-02\n",
      "fold3  4.09e-02  0.02  0.03  4.95e-02\n",
      "fold4  2.20e-02  0.04  0.03  6.00e-03\n",
      "fold5  2.71e-02  0.03  0.03  3.93e-02\n"
     ]
    }
   ],
   "source": [
    "subgroups = {\n",
    "            'e':['B', 'A', 'W', 'I'],\n",
    "            'g':['F','M'],\n",
    "            'att': ['black_females', 'black_males', 'asian_females', 'asian_males', 'white_females', 'white_males', 'indian_females', 'indian_males']\n",
    "        }\n",
    "att = 'e'   \n",
    "test = load_measures('bfw','facenet-webface','faircal',subgroups, att,'ks','beta', 25, 100)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sensitive_attributes_subgroups(dataset):\n",
    "    if dataset == 'rfw':\n",
    "        sensitive_attributes = ['ethnicity']\n",
    "        subgroups = {'ethnicity':['African', 'Asian', 'Caucasian', 'Indian']}\n",
    "    elif 'bfw' in dataset:\n",
    "        sensitive_attributes = ['e', 'g', 'att']\n",
    "        subgroups = {\n",
    "            'e':['B', 'A', 'W', 'I'],\n",
    "            'g':['F','M'],\n",
    "            'att': ['black_females', 'black_males', 'asian_females', 'asian_males', 'white_females', 'white_males', 'indian_females', 'indian_males']\n",
    "        }\n",
    "    return sensitive_attributes, subgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  mean   aad   mad   std\n",
      "dataset feature         attribute      approach                         \n",
      "rfw     facenet         African        baseline   6.29  0.56  1.00  0.61\n",
      "                                       faircal    1.72  0.50  0.73  0.55\n",
      "                        Asian          baseline   5.66  0.40  0.63  0.43\n",
      "                                       faircal    1.70  0.48  0.86  0.56\n",
      "                        Caucasian      baseline  11.22  0.85  1.09  0.91\n",
      "                                       faircal    1.53  0.35  0.57  0.40\n",
      "                        Indian         baseline   1.99  0.91  1.63  0.98\n",
      "                                       faircal    1.99  0.71  1.52  0.89\n",
      "        facenet-webface African        baseline   4.32  0.59  1.46  0.76\n",
      "                                       faircal    1.67  0.21  0.35  0.23\n",
      "                        Asian          baseline   5.34  0.33  0.80  0.44\n",
      "                                       faircal    1.78  0.44  0.84  0.51\n",
      "                        Caucasian      baseline  10.16  0.42  0.80  0.50\n",
      "                                       faircal    1.74  0.50  0.80  0.57\n",
      "                        Indian         baseline   2.39  1.07  2.03  1.26\n",
      "                                       faircal    2.16  0.83  1.84  1.07\n",
      "bfw     facenet-webface B              baseline   1.69  0.76  1.65  0.91\n",
      "                                       faircal    2.44  0.77  1.65  1.02\n",
      "                        A              baseline   3.58  0.67  1.63  0.95\n",
      "                                       faircal    2.66  0.93  1.49  1.04\n",
      "                        W              baseline   8.80  0.82  1.81  1.00\n",
      "                                       faircal    2.55  0.42  0.83  0.51\n",
      "                        I              baseline   2.13  0.94  1.94  1.09\n",
      "                                       faircal    2.70  1.40  2.26  1.56\n",
      "                        F              baseline   1.45  0.51  1.22  0.65\n",
      "                                       faircal    1.81  0.51  0.94  0.59\n",
      "                        M              baseline   1.74  0.51  1.12  0.66\n",
      "                                       faircal    1.45  0.57  1.25  0.72\n",
      "                        black_females  baseline   4.65  1.20  1.82  1.34\n",
      "                                       faircal    3.99  1.17  1.62  1.24\n",
      "                        black_males    baseline   2.00  0.63  0.83  0.66\n",
      "                                       faircal    2.56  1.27  2.13  1.41\n",
      "                        asian_females  baseline   7.68  2.07  2.97  2.23\n",
      "                                       faircal    3.75  1.72  2.77  1.85\n",
      "                        asian_males    baseline   2.67  0.57  1.20  0.74\n",
      "                                       faircal    4.28  0.98  2.11  1.20\n",
      "                        white_females  baseline  12.05  0.55  1.18  0.68\n",
      "                                       faircal    3.89  0.70  1.08  0.76\n",
      "                        white_males    baseline   8.15  1.27  3.01  1.60\n",
      "                                       faircal    2.53  0.85  1.31  0.88\n",
      "                        indian_females baseline   3.54  0.67  1.47  0.81\n",
      "                                       faircal    3.74  1.81  3.38  2.12\n",
      "                        indian_males   baseline   4.03  1.86  3.12  1.96\n",
      "                                       faircal    3.35  1.65  2.09  1.70\n"
     ]
    }
   ],
   "source": [
    "# Fairness calibration table\n",
    "\n",
    "ks = np.array([5,10,15,20,25,50,75,100])\n",
    "folds = [1,2,3,4,5]\n",
    "data = pd.DataFrame()\n",
    "\n",
    "measure = 'ks'\n",
    "calibration = 'beta'\n",
    "\n",
    "indices = {\n",
    "    'rfw' : {\n",
    "        'facenet': ['African', 'Asian', 'Caucasian', 'Indian'],\n",
    "        'facenet-webface': ['African', 'Asian', 'Caucasian', 'Indian'],\n",
    "    },\n",
    "    'bfw' : {\n",
    "        'facenet-webface': ['B', 'A', 'W', 'I', 'F','M', \n",
    "            'black_females', 'black_males', 'asian_females', 'asian_males', 'white_females', 'white_males', 'indian_females', 'indian_males']\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Create tuples from multi-indices\n",
    "approaches = ['baseline', 'faircal']\n",
    "tuples = []\n",
    "for dataset in indices:\n",
    "    for feature, sens in indices[dataset].items():\n",
    "        for att in sens:\n",
    "            for approach in approaches:\n",
    "                tuples.append((dataset, feature, att, approach))\n",
    "\n",
    "index = pd.MultiIndex.from_tuples(tuples, names=['dataset', 'feature', 'attribute', 'approach'])\n",
    "\n",
    "data = pd.DataFrame(index=index)\n",
    "for metric in ['mean', 'aad', 'mad', 'std']:\n",
    "    data[metric] = np.nan\n",
    "\n",
    "# For now, because we only have one experiment\n",
    "for dataset in indices:\n",
    "    for feature in indices[dataset]:\n",
    "        for approach in approaches:\n",
    "            sensitive_attributes, subgroups = get_sensitive_attributes_subgroups(dataset)\n",
    "            for att in sensitive_attributes:\n",
    "                nbins = 25 if dataset == 'bfw' else 10\n",
    "                data_work = load_measures(dataset, feature, approach, subgroups, att, 'ks', 'beta', nbins=nbins, n_clusters=100)\n",
    "                data_work = data_work * 100\n",
    "                for subgroup in data_work.columns:\n",
    "                    group_mean = data_work[subgroup].mean()\n",
    "                    data.loc[dataset, feature, subgroup, approach]['mean'] = group_mean\n",
    "                    data.loc[dataset, feature, subgroup, approach]['aad'] = np.abs(data_work[subgroup] - group_mean).mean()\n",
    "                    data.loc[dataset, feature, subgroup, approach]['mad'] = np.abs(data_work[subgroup] - group_mean).max()\n",
    "                    data.loc[dataset, feature, subgroup, approach]['std'] = np.std(data_work[subgroup])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global accuracy measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_overall_stats(calibration_method, nbins, dataset, feature, approach, att, n_clusters, fpr_def):\n",
    "    filename = f'../experiments/{dataset}/{feature}/{approach}/{calibration_method}/nbins_{nbins}'\n",
    "    if approach == 'faircal':\n",
    "        filename += f'_nclusters_{n_clusters}'\n",
    "    if approach == 'fsn':\n",
    "        filename += f'_nclusters_{n_clusters}_fpr_1e-03'\n",
    "    key = 'calibration' if approach in ['faircal', 'baseline'] else 'pre_calibration'\n",
    "    \n",
    "    results = np.load(f'{filename}.npy', allow_pickle=True).item()\n",
    "\n",
    "    data = pd.DataFrame()\n",
    "    data['folds'] = ['fold1', 'fold2', 'fold3', 'fold4', 'fold5']\n",
    "    data['auc'] = np.nan\n",
    "    data['fpr_1e-3'] = np.nan\n",
    "    data['fpr_1e-2'] = np.nan\n",
    "    data = data.set_index('folds')\n",
    "\n",
    "    for fold in range(1,6):\n",
    "        fpr = results['fold'+str(fold)]['fpr'][att]['Global'][key]\n",
    "        tpr = results['fold'+str(fold)]['tpr'][att]['Global'][key]\n",
    "        data.loc[f'fold{str(fold)}', 'auc'] = sklearn.metrics.auc(fpr,tpr)\n",
    "        inter = np.interp(fpr_def, fpr, tpr)\n",
    "        data.iloc[fold-1, 1:] = inter\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           auc      fpr_1e-3      fpr_1e-2\n",
      "dataset feature         approach                                          \n",
      "rfw     facenet         baseline  89.97 (0.58)  25.27 (6.51)   39.92 (2.4)\n",
      "                        faircal   92.16 (0.43)  29.46 (4.65)  49.95 (4.08)\n",
      "        facenet-webface baseline  84.46 (0.47)  11.14 (5.34)   26.45 (4.9)\n",
      "                        faircal    86.9 (0.73)  19.54 (4.38)  35.05 (4.55)\n",
      "bfw     facenet-webface baseline  95.17 (0.16)  30.23 (1.63)  55.11 (1.25)\n",
      "                        faircal   96.05 (0.13)  40.24 (0.26)  62.59 (0.66)\n"
     ]
    }
   ],
   "source": [
    "# Accuracy table\n",
    "keys = ['baseline', 'faircal']\n",
    "error = [1e-3, 1e-2]\n",
    "title_stat = ['AUROC', '0.1\\% FPR', '1\\% FPR']\n",
    "n_clusters = 100\n",
    "calibration = 'beta'\n",
    "datasets = ['bfw', 'rfw']\n",
    "\n",
    "indices = {\n",
    "    'rfw' : ['facenet', 'facenet-webface'],\n",
    "    'bfw' : ['facenet-webface']\n",
    "}\n",
    "approaches = ['baseline', 'faircal']\n",
    "\n",
    "tuples = []\n",
    "for dataset in indices:\n",
    "    for feature in indices[dataset]:\n",
    "        for approach in approaches:\n",
    "            tuples.append((dataset, feature, approach))\n",
    "\n",
    "index = pd.MultiIndex.from_tuples(tuples, names=['dataset', 'feature', 'approach'])\n",
    "data = pd.DataFrame(index=index)\n",
    "metrics = ['auc', 'fpr_1e-3', 'fpr_1e-2']\n",
    "for metric in metrics:\n",
    "    data[metric] = ''\n",
    "\n",
    "for dataset in indices:\n",
    "    for feature in indices[dataset]:\n",
    "        for approach in approaches:\n",
    "            nbins = 25 if dataset == 'bfw' else 10\n",
    "            att = 'att' if dataset == 'bfw' else 'ethnicity'\n",
    "            data_work = get_overall_stats(calibration, nbins, dataset, feature, approach, att, n_clusters,error)\n",
    "            data_work *= 100\n",
    "            for metric in metrics:\n",
    "                mean = round(data_work[metric].mean(), 2)\n",
    "                std = round(data_work[metric].std(), 2)\n",
    "                data.loc[dataset, feature, approach][metric] = f'{str(mean)} ({str(std)})'\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing Ryan's old vs new versions of an experiment\n",
    "\n",
    "# def get_overall_stats_temp(calibration_method, nbins, dataset,feature,approach,att,n_clusters,fpr_def, new):\n",
    "#     filename = f'../experiments/{dataset}/{feature}/{approach}/{calibration_method}/nbins_{nbins}'\n",
    "#     if approach == 'faircal':\n",
    "#         filename += f'_nclusters_{n_clusters} ({new})'\n",
    "#     if approach == 'fsn':\n",
    "#         filename += f'_nclusters_{n_clusters}_fpr_1e-03'\n",
    "#     key = 'calibration' if approach in ['faircal', 'baseline'] else 'pre_calibration'\n",
    "    \n",
    "#     results = np.load(f'{filename}.npy', allow_pickle=True).item()\n",
    "\n",
    "#     data = pd.DataFrame()\n",
    "#     data['folds'] = ['fold1', 'fold2', 'fold3', 'fold4', 'fold5']\n",
    "#     data['auc'] = np.nan\n",
    "#     data['fpr_1e-3'] = np.nan\n",
    "#     data['fpr_1e-2'] = np.nan\n",
    "#     data = data.set_index('folds')\n",
    "\n",
    "#     for fold in range(1,6):\n",
    "#         fpr = results['fold'+str(fold)]['fpr'][att]['Global'][key]\n",
    "#         tpr = results['fold'+str(fold)]['tpr'][att]['Global'][key]\n",
    "#         data.loc[f'fold{str(fold)}', 'auc'] = sklearn.metrics.auc(fpr,tpr)\n",
    "#         inter = np.interp(fpr_def, fpr, tpr)\n",
    "#         data.iloc[fold-1, 1:] = inter\n",
    "#     return data\n",
    "\n",
    "# # Accuracy table\n",
    "# keys = ['baseline', 'faircal']\n",
    "# error = [1e-3, 1e-2]\n",
    "# title_stat = ['AUROC', '0.1\\% FPR', '1\\% FPR']\n",
    "# n_clusters = 100\n",
    "# calibration = 'beta'\n",
    "\n",
    "# version = ['new', 'old']\n",
    "# data = pd.DataFrame(index=version)\n",
    "# metrics = ['auc', 'fpr_1e-3', 'fpr_1e-2']\n",
    "# for metric in metrics:\n",
    "#     data[metric] = ''\n",
    "\n",
    "# dataset = 'bfw'\n",
    "# feature = 'facenet-webface'\n",
    "# approach = 'faircal'\n",
    "\n",
    "# for current in version:\n",
    "#     nbins = 25 if dataset == 'bfw' else 10\n",
    "#     att = 'att' if dataset == 'bfw' else 'ethnicity'\n",
    "#     data_work = get_overall_stats_temp(calibration, nbins, dataset, feature, approach, att ,n_clusters,error, current)\n",
    "#     data_work *= 100\n",
    "#     for metric in metrics:\n",
    "#         mean = round(data_work[metric].mean(), 2)\n",
    "#         std = round(data_work[metric].std(), 2)\n",
    "#         data.loc[current][metric] = f'{str(mean)} ({str(std)})'\n",
    "\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictive Equality ('fpr at fpr') and Equal Opportunity ('fnr at fnr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error1_at_error2(calibration_method, dataset, feature, approach, subgroup, n_clusters, errors, at_error):\n",
    "    nbins = 25 if dataset == 'bfw' else 10\n",
    "    att = 'att' if dataset == 'bfw' else 'ethnicity'\n",
    "\n",
    "    filename = f'../experiments/{dataset}/{feature}/{approach}/{calibration_method}/nbins_{nbins}'\n",
    "    if approach == 'faircal':\n",
    "        filename += f'_nclusters_{n_clusters}'\n",
    "    if approach == 'fsn':\n",
    "        filename += f'_nclusters_{n_clusters}_fpr_1e-03'\n",
    "    key = 'calibration' if approach in ['faircal', 'oracle'] else 'pre_calibration' \n",
    "    \n",
    "    results = np.load(f'{filename}.npy', allow_pickle=True).item()\n",
    "    \n",
    "    data = pd.DataFrame()\n",
    "    data['folds'] = ['fold1', 'fold2', 'fold3', 'fold4', 'fold5']\n",
    "\n",
    "    data[at_error] = np.nan\n",
    "    data = data.set_index('folds')\n",
    "\n",
    "    for fold in range(1,6):\n",
    "        if subgroup == 'Global':\n",
    "            fpr = results['fold'+str(fold)]['fpr'][att][subgroup][key]\n",
    "            tpr = results['fold'+str(fold)]['tpr'][att][subgroup][key]\n",
    "\n",
    "            if errors == 'fnr at fpr':\n",
    "                data.iloc[fold-1,:] = 1-np.interp(at_error, fpr, tpr)\n",
    "            elif errors == 'fpr at fpr' or errors == 'fnr at fnr':\n",
    "                data.iloc[fold-1,:] = at_error\n",
    "            elif errors == 'fpr at fnr':\n",
    "                data.iloc[fold-1,:] = np.interp(1-np.array(at_error), tpr, fpr)\n",
    "        else:\n",
    "            fpr_global = results['fold'+str(fold)]['fpr'][att]['Global'][key]\n",
    "            tpr_global = results['fold'+str(fold)]['tpr'][att]['Global'][key]\n",
    "            thr_global = np.fmin(results['fold'+str(fold)]['thresholds'][att]['Global'][key], 1)\n",
    "\n",
    "            fpr = results['fold'+str(fold)]['fpr'][att][subgroup][key]\n",
    "            tpr = results['fold'+str(fold)]['tpr'][att][subgroup][key]\n",
    "            thr = results['fold'+str(fold)]['thresholds'][att][subgroup][key]\n",
    "            thr = np.fmin(thr, 1)\n",
    "            \n",
    "            if errors == 'fnr at fpr':\n",
    "                thr_at_error = np.interp(at_error,fpr_global,thr_global)\n",
    "                data.iloc[fold-1,:] = 1-np.interp(thr_at_error,thr[::-1],tpr[::-1])\n",
    "            elif errors == 'fpr at fpr':\n",
    "                thr_at_error = np.interp(at_error,fpr_global,thr_global)\n",
    "                data.iloc[fold-1,:] = np.interp(thr_at_error,thr[::-1],fpr[::-1])\n",
    "            elif errors == 'fpr at fnr':\n",
    "                thr_at_error = np.interp(1-np.array(at_error),tpr_global,thr_global)\n",
    "                data.iloc[fold-1,:] = np.interp(thr_at_error,thr[::-1],fpr[::-1])\n",
    "            elif errors == 'fnr at fnr':\n",
    "                thr_at_error = np.interp(1-np.array(at_error),tpr_global,thr_global)\n",
    "                data.iloc[fold-1,:] = 1-np.interp(thr_at_error,thr[::-1],tpr[::-1])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0.001\n",
      "folds          \n",
      "fold1  4.10e-03\n",
      "fold2  5.02e-03\n",
      "fold3  1.86e-03\n",
      "fold4  6.53e-04\n",
      "fold5  9.56e-04\n"
     ]
    }
   ],
   "source": [
    "# Example test\n",
    "\n",
    "calibration_method = 'beta' \n",
    "dataset = 'rfw' \n",
    "feature = 'facenet-webface' \n",
    "approach = 'baseline' \n",
    "# subgroup = 'Global' \n",
    "subgroup = 'Asian'\n",
    "n_clusters = 100\n",
    "errors = 'fpr at fpr'\n",
    "at_fpr = 1e-3\n",
    "\n",
    "data = get_error1_at_error2(calibration_method, dataset, feature, approach, subgroup, n_clusters, errors, at_fpr)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_df_for(objective, global_error):\n",
    "    calibration_method = 'beta'\n",
    "    approaches = ['baseline', 'faircal']\n",
    "    n_clusters = 100\n",
    "    \n",
    "    errors = 'fpr at fpr' if objective == 'predictive_equality' else 'fnr at fnr'\n",
    "\n",
    "    datasets = ['bfw', 'rfw']\n",
    "    indices = {\n",
    "        'rfw' : ['facenet', 'facenet-webface'],\n",
    "        'bfw' : ['facenet-webface', 'arcface']\n",
    "    }\n",
    "\n",
    "    tuples = []\n",
    "    for dataset in indices:\n",
    "        for feature in indices[dataset]:\n",
    "            for approach in approaches:\n",
    "                tuples.append((dataset, feature, approach))\n",
    "\n",
    "    index = pd.MultiIndex.from_tuples(tuples, names=['dataset', 'feature', 'approach'])\n",
    "    data = pd.DataFrame(index=index, dtype=\"string\")\n",
    "    metrics = ['aad', 'mad', 'std']\n",
    "    for metric in metrics:\n",
    "        data[metric] = ''\n",
    "\n",
    "    for dataset in indices:\n",
    "        att = attributes_datasets[dataset]\n",
    "        _, subgroups = get_sensitive_attributes_subgroups(dataset)    \n",
    "        for feature in indices[dataset]:\n",
    "            for approach in approaches:\n",
    "                folds_x_subgroups = pd.DataFrame() \n",
    "                for i, subgroup in enumerate(subgroups[att]):\n",
    "                    folds_x_subgroups[subgroup] = get_error1_at_error2(calibration_method, dataset, feature, approach, subgroup, n_clusters, errors, global_error)  \n",
    "\n",
    "                # computing metrics for averaged over each subgroup\n",
    "                mean = folds_x_subgroups.mean(axis=1)\n",
    "                data_work = {'aad': folds_x_subgroups.sub(mean, axis=0).abs().mean(axis=1),\n",
    "                             'mad': folds_x_subgroups.sub(mean, axis=0).abs().max(axis=1),\n",
    "                             'std': folds_x_subgroups.std(axis=1)\n",
    "                            }\n",
    "\n",
    "                # putting values in the data table\n",
    "                for metric in metrics:\n",
    "                    mean = round(data_work[metric].mean() * 100, 2) \n",
    "                    std = round(data_work[metric].std() * 100, 2)\n",
    "                    data.loc[dataset, feature, approach][metric] = f'{mean} ({std})'\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising example results for predictive equality and equal opportunity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "predictive equality at a global error rate = 0.1%\n",
      "                                          aad          mad          std\n",
      "dataset feature         approach                                       \n",
      "rfw     facenet         baseline  0.14 (0.01)  0.27 (0.02)  0.18 (0.02)\n",
      "                        faircal   0.13 (0.01)  0.27 (0.03)  0.18 (0.02)\n",
      "        facenet-webface baseline  0.09 (0.03)  0.18 (0.07)  0.12 (0.04)\n",
      "                        faircal   0.13 (0.01)  0.26 (0.02)  0.17 (0.02)\n",
      "bfw     facenet-webface baseline  0.09 (0.02)  0.24 (0.08)  0.12 (0.03)\n",
      "                        faircal    0.1 (0.01)  0.27 (0.09)  0.13 (0.02)\n",
      "        arcface         baseline   0.1 (0.03)  0.29 (0.15)  0.14 (0.05)\n",
      "                        faircal   0.11 (0.03)  0.36 (0.18)  0.16 (0.06)\n",
      "\n",
      "predictive equality at a global error rate = 1.0%\n",
      "                                          aad          mad          std\n",
      "dataset feature         approach                                       \n",
      "rfw     facenet         baseline  0.53 (0.13)  0.97 (0.36)  0.72 (0.23)\n",
      "                        faircal   0.37 (0.13)  0.61 (0.22)  0.48 (0.16)\n",
      "        facenet-webface baseline  0.44 (0.23)  0.79 (0.51)  0.58 (0.33)\n",
      "                        faircal   0.44 (0.09)  0.81 (0.16)   0.6 (0.11)\n",
      "bfw     facenet-webface baseline   0.5 (0.09)  0.98 (0.21)  0.61 (0.11)\n",
      "                        faircal   0.44 (0.16)   0.89 (0.3)  0.55 (0.17)\n",
      "        arcface         baseline  0.56 (0.22)   1.6 (0.77)  0.79 (0.31)\n",
      "                        faircal   0.74 (0.13)  2.01 (0.73)  1.02 (0.21)\n",
      "\n",
      "equal opportunity at a global error rate = 0.1%\n",
      "                                          aad          mad          std\n",
      "dataset feature         approach                                       \n",
      "rfw     facenet         baseline  0.14 (0.01)  0.27 (0.02)  0.18 (0.02)\n",
      "                        faircal   0.13 (0.01)  0.27 (0.03)  0.18 (0.02)\n",
      "        facenet-webface baseline  0.09 (0.03)  0.18 (0.07)  0.12 (0.04)\n",
      "                        faircal   0.13 (0.01)  0.26 (0.02)  0.17 (0.02)\n",
      "bfw     facenet-webface baseline  0.09 (0.02)  0.24 (0.08)  0.12 (0.03)\n",
      "                        faircal    0.1 (0.01)  0.27 (0.09)  0.13 (0.02)\n",
      "        arcface         baseline   0.1 (0.03)  0.29 (0.15)  0.14 (0.05)\n",
      "                        faircal   0.11 (0.03)  0.36 (0.18)  0.16 (0.06)\n",
      "\n",
      "equal opportunity at a global error rate = 1.0%\n",
      "                                          aad          mad          std\n",
      "dataset feature         approach                                       \n",
      "rfw     facenet         baseline  0.53 (0.13)  0.97 (0.36)  0.72 (0.23)\n",
      "                        faircal   0.37 (0.13)  0.61 (0.22)  0.48 (0.16)\n",
      "        facenet-webface baseline  0.44 (0.23)  0.79 (0.51)  0.58 (0.33)\n",
      "                        faircal   0.44 (0.09)  0.81 (0.16)   0.6 (0.11)\n",
      "bfw     facenet-webface baseline   0.5 (0.09)  0.98 (0.21)  0.61 (0.11)\n",
      "                        faircal   0.44 (0.16)   0.89 (0.3)  0.55 (0.17)\n",
      "        arcface         baseline  0.56 (0.22)   1.6 (0.77)  0.79 (0.31)\n",
      "                        faircal   0.74 (0.13)  2.01 (0.73)  1.02 (0.21)\n"
     ]
    }
   ],
   "source": [
    "objectives = ['predictive equality', 'equal opportunity']\n",
    "global_errors = [1e-3, 1e-2]\n",
    "\n",
    "for objective in objectives:\n",
    "    for global_error in global_errors:\n",
    "        current_df = produce_df_for(objective, global_error)\n",
    "        print(f'\\n{objective} at a global error rate = {global_error * 100}%')                \n",
    "        print(current_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example conversion from pandas to latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "    &         &         &          aad &          mad &          std \\\\\n",
      "dataset & feature & approach &              &              &              \\\\\n",
      "\\midrule\n",
      "rfw & facenet & baseline &  0.53 (0.13) &  0.97 (0.36) &  0.72 (0.23) \\\\\n",
      "    &         & faircal &  0.37 (0.13) &  0.61 (0.22) &  0.48 (0.16) \\\\\n",
      "    & facenet-webface & baseline &  0.44 (0.23) &  0.79 (0.51) &  0.58 (0.33) \\\\\n",
      "    &         & faircal &  0.44 (0.09) &  0.81 (0.16) &   0.6 (0.11) \\\\\n",
      "bfw & facenet-webface & baseline &   0.5 (0.09) &  0.98 (0.21) &  0.61 (0.11) \\\\\n",
      "    &         & faircal &  0.44 (0.16) &   0.89 (0.3) &  0.55 (0.17) \\\\\n",
      "    & arcface & baseline &  0.56 (0.22) &   1.6 (0.77) &  0.79 (0.31) \\\\\n",
      "    &         & faircal &  0.74 (0.13) &  2.01 (0.73) &  1.02 (0.21) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ns/ywvr68ys7ln1r7pltrqvxv4w0000gn/T/ipykernel_79290/957775366.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  txt = current_df.to_latex()\n"
     ]
    }
   ],
   "source": [
    "txt = current_df.to_latex()\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "38bfd7062c2e40c254718556666e4422f04be01044787720715af94b520c2c5e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
