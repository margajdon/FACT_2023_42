{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tables for FairCal based on Salvador et al., 2022\n",
    "## Reproduced by Group 42 of FACT-AI 2022/23 @ UvA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tables Reproduced\n",
    "\n",
    "1. Global Accuracy Measures\n",
    "2. Fairness Calibration\n",
    "3. Predictive Equality ('fpr at fpr')\n",
    "4. Equal Opportunity ('fnr at fnr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.precision\", 2)\n",
    "import seaborn as sns\n",
    "import sklearn.metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Manager to load pickle files and provide data based on specific table of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataManager:\n",
    "    '''\n",
    "    This class stores the information about the data corresponding to a specific dataset, feature, approach, and objective combination, among other factors.\n",
    "    Input: \n",
    "        dataset (str), e.g. 'rfw'\n",
    "        feature (str), e.g. 'facenet'\n",
    "        approach (str), e.g. 'faircal'\n",
    "        objective (str), e.g. 'accuracy'\n",
    "        ...\n",
    "        \n",
    "    Methods\n",
    "        load_pickle: loads a pickle file into a results dictionary\n",
    "        provide_data: returns a dataframe based on pre-specified objective and other self attributes\n",
    "        get_sensitive_attributes_subgroups: returns a list of sensitive attributes and a dictionary with keys = sensitive attributes and values = subgroups imposed by that attribute\n",
    "\n",
    "    '''\n",
    "    def __init__(self, dataset, feature, approach, objective, calibration_method='beta', n_clusters=100, measure='ece', at_error='1e-2', subgroup='African', fpr_def=[1e-3, 1e-2]):\n",
    "        self.dataset = dataset\n",
    "        self.feature = feature\n",
    "        self.approach = approach\n",
    "        self.objective = objective\n",
    "        self.calibration_method = calibration_method\n",
    "        self.n_clusters = n_clusters\n",
    "        self.measure = measure\n",
    "        self.at_error = at_error\n",
    "        self.subgroup = subgroup\n",
    "        self.fpr_def = fpr_def\n",
    "        self.errors = 'fpr at fpr' if objective == 'predictive_equality' else 'fnr at fnr'\n",
    "        self.nbins = 25 if dataset == 'bfw' else 10\n",
    "        self.att = 'att' if dataset == 'bfw' else 'ethnicity'\n",
    "        self.key = 'calibration' if approach in ['faircal', 'baseline', 'gmm-discrete', 'oracle'] else 'pre_calibration'\n",
    "        self.sensitive_attributes, self.subgroups = self.get_sensitive_attributes_subgroups(self.dataset)\n",
    "        self.load_pickle()        \n",
    "\n",
    "    def load_pickle(self):\n",
    "        filename = f'../experiments/{self.dataset}/{self.feature}/{self.approach}/{self.calibration_method}/nbins_{self.nbins}'\n",
    "        if self.approach in ['faircal', 'gmm-discrete'] :\n",
    "            filename += f'_nclusters_{self.n_clusters}'\n",
    "        if self.approach == 'fsn':\n",
    "            filename += f'_nclusters_{self.n_clusters}_fpr_1e-03'\n",
    "        self.results = np.load(f'{filename}.npy', allow_pickle=True).item()\n",
    "\n",
    "    def provide_data(self, objective):\n",
    "        data = pd.DataFrame()\n",
    "        data['folds'] = ['fold1', 'fold2', 'fold3', 'fold4', 'fold5']\n",
    "        data = data.set_index('folds')\n",
    "        \n",
    "        if self.objective == 'accuracy':\n",
    "            data['AUROC'] = np.nan\n",
    "            data['TPR @ 0.1% FPR'] = np.nan\n",
    "            data['TPR @ 1% FPR'] = np.nan\n",
    "            for fold in range(1,6):\n",
    "                fpr = self.results['fold'+str(fold)]['fpr'][self.att]['Global'][self.key]\n",
    "                tpr = self.results['fold'+str(fold)]['tpr'][self.att]['Global'][self.key]\n",
    "                data.loc[f'fold{str(fold)}', 'AUROC'] = sklearn.metrics.auc(fpr,tpr)\n",
    "                inter = np.interp(self.fpr_def, fpr, tpr)\n",
    "                data.iloc[fold-1, 1:] = inter\n",
    "        \n",
    "        elif self.objective == 'fairness_calibration':\n",
    "            for fold in range(1, 6):\n",
    "                for sensitive_attribute in self.sensitive_attributes:\n",
    "                    for subgroup in self.subgroups[sensitive_attribute]:\n",
    "                        data.loc[f'fold{str(fold)}', f'{subgroup}'] = self.results[f'fold{str(fold)}'][self.measure][sensitive_attribute][subgroup]\n",
    "      \n",
    "        elif self.objective == 'predictive_equality' or objective == 'equal_opportunity':\n",
    "            data[self.at_error] = np.nan\n",
    "            \n",
    "            for fold in range(1,6):\n",
    "                if self.subgroup == 'Global':\n",
    "                    data.iloc[fold-1,:] = self.at_error\n",
    "                else:\n",
    "                    fpr_global = self.results['fold'+str(fold)]['fpr'][self.att]['Global'][self.key]\n",
    "                    tpr_global = self.results['fold'+str(fold)]['tpr'][self.att]['Global'][self.key]\n",
    "                    thr_global = np.fmin(self.results['fold'+str(fold)]['thresholds'][self.att]['Global'][self.key], 1)\n",
    "\n",
    "                    fpr = self.results['fold'+str(fold)]['fpr'][self.att][self.subgroup][self.key]\n",
    "                    tpr = self.results['fold'+str(fold)]['tpr'][self.att][self.subgroup][self.key]\n",
    "                    thr = np.fmin(self.results['fold'+str(fold)]['thresholds'][self.att][self.subgroup][self.key], 1)\n",
    "\n",
    "                    if self.errors == 'fpr at fpr':\n",
    "                        thr_at_error = np.interp(self.at_error,fpr_global,thr_global)\n",
    "                        data.iloc[fold-1,:] = np.interp(thr_at_error,thr[::-1],fpr[::-1])\n",
    "                    elif self.errors == 'fnr at fnr':\n",
    "                        thr_at_error = np.interp(1-np.array(self.at_error),tpr_global,thr_global)\n",
    "                        data.iloc[fold-1,:] = 1-np.interp(thr_at_error,thr[::-1],tpr[::-1])  \n",
    "        else:\n",
    "            print('Please specify a valid objective.')\n",
    "        return data\n",
    "\n",
    "    @staticmethod\n",
    "    def get_sensitive_attributes_subgroups(dataset):\n",
    "        '''\n",
    "        A helper function to get sensitive attributes per subgroup, depending on the dataset.\n",
    "        \n",
    "        '''\n",
    "        if dataset == 'rfw':\n",
    "            sensitive_attributes = ['ethnicity']\n",
    "            subgroups = {'ethnicity':['African', 'Asian', 'Caucasian', 'Indian']}\n",
    "        else:\n",
    "            sensitive_attributes = ['e', 'g', 'att']\n",
    "            subgroups = {\n",
    "                'e':['B', 'A', 'W', 'I'],\n",
    "                'g':['F','M'],\n",
    "                'att': ['black_females', 'black_males', 'asian_females', 'asian_males', 'white_females', 'white_males', 'indian_females', 'indian_males']\n",
    "            }\n",
    "        return sensitive_attributes, subgroups\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A general multi-index table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multi_table(objective, setting='global'):\n",
    "#     approaches = ['baseline', 'agenda', 'fsn', 'faircal', 'oracle']\n",
    "    approaches = ['baseline', 'faircal']\n",
    "    tuples = []\n",
    "    \n",
    "    if objective == 'fairness_calibration':\n",
    "        indices = {\n",
    "        'rfw' : {\n",
    "            'facenet': ['African', 'Asian', 'Caucasian', 'Indian'],\n",
    "            'facenet-webface': ['African', 'Asian', 'Caucasian', 'Indian'],\n",
    "        },\n",
    "        'bfw' : {\n",
    "            'facenet-webface': ['B', 'A', 'W', 'I', 'F','M', \n",
    "                'black_females', 'black_males', 'asian_females', 'asian_males', 'white_females', 'white_males', 'indian_females', 'indian_males'],\n",
    "            'arcface': ['B', 'A', 'W', 'I', 'F','M', \n",
    "                'black_females', 'black_males', 'asian_females', 'asian_males', 'white_females', 'white_males', 'indian_females', 'indian_males'],\n",
    "            },\n",
    "#             'bfw' : {\n",
    "#             'facenet-webface': ['black_females', 'black_males', 'asian_females', 'asian_males', 'white_females', 'white_males', 'indian_females', 'indian_males'],\n",
    "#             'arcface': ['black_females', 'black_males', 'asian_females', 'asian_males', 'white_females', 'white_males', 'indian_females', 'indian_males'],\n",
    "#             },\n",
    "        }\n",
    "        if setting == 'show_subgroups':\n",
    "            for dataset in indices:\n",
    "                for feature, sens in indices[dataset].items():\n",
    "                    for att in sens:\n",
    "                        for approach in approaches:\n",
    "                            tuples.append((dataset, feature, att, approach))\n",
    "            index = pd.MultiIndex.from_tuples(tuples, names=['dataset', 'feature', 'subgroup', 'approach'])\n",
    "        else:\n",
    "            for dataset in indices:\n",
    "                for feature in indices[dataset]:\n",
    "                    for approach in approaches:\n",
    "                        tuples.append((dataset, feature, approach))\n",
    "            index = pd.MultiIndex.from_tuples(tuples, names=['dataset', 'feature', 'approach'])\n",
    "            \n",
    "    \n",
    "    else:\n",
    "        indices = {\n",
    "        'rfw' : ['facenet', 'facenet-webface'],\n",
    "        'bfw' : ['facenet-webface', 'arcface']\n",
    "        }\n",
    "        for dataset in indices:\n",
    "            for feature in indices[dataset]:\n",
    "                for approach in approaches:\n",
    "                    tuples.append((dataset, feature, approach))\n",
    "        index = pd.MultiIndex.from_tuples(tuples, names=['dataset', 'feature', 'approach'])\n",
    "    \n",
    "    data = pd.DataFrame(index=index)\n",
    "    return approaches, indices, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_for(objective, global_error=1e-2, setting='global'):\n",
    "    approaches, indices, data = create_multi_table(objective=objective, setting=setting)\n",
    "    \n",
    "    if objective == 'accuracy':\n",
    "        metrics = ['AUROC', 'TPR @ 0.1% FPR', 'TPR @ 1% FPR']\n",
    "        for metric in metrics:\n",
    "            data[metric] = ''\n",
    "        error = [1e-3, 1e-2]\n",
    "    \n",
    "        for dataset in indices:\n",
    "            for feature in indices[dataset]:\n",
    "                for approach in approaches:\n",
    "                    data_object = DataManager(dataset, feature, approach, objective, fpr_def=error)\n",
    "                    data_work = data_object.provide_data(objective)\n",
    "                    data_work *= 100\n",
    "                    for metric in metrics:\n",
    "                        mean = '%.2f' % data_work[metric].mean()\n",
    "                        std = '%.2f' % data_work[metric].std()\n",
    "                        data.loc[dataset, feature, approach][metric] = f'{str(mean)} ({str(std)})'\n",
    "    \n",
    "    elif objective == 'fairness_calibration':\n",
    "        metrics = ['mean', 'aad', 'mad', 'std']\n",
    "        \n",
    "        if setting == 'show_subgroups':\n",
    "            for metric in metrics:\n",
    "                data[metric] = np.nan\n",
    "            for dataset in indices:\n",
    "                for feature in indices[dataset]:\n",
    "                    for approach in approaches:\n",
    "                        sensitive_attributes = indices[dataset][feature]\n",
    "                        for att in sensitive_attributes:\n",
    "                            data_object = DataManager(dataset, feature, approach, objective)\n",
    "                            data_work = data_object.provide_data(objective)\n",
    "                            data_work = data_work * 100\n",
    "                            for subgroup in data_work.columns:\n",
    "                                loc_select = data.loc[dataset, feature, subgroup, approach]\n",
    "                                group_mean = data_work[subgroup].mean()\n",
    "                                loc_select['mean'] = group_mean\n",
    "                                loc_select['aad'] = np.abs(data_work[subgroup] - group_mean).mean()\n",
    "                                loc_select['mad'] = np.abs(data_work[subgroup] - group_mean).max()\n",
    "                                loc_select['std'] = np.std(data_work[subgroup])\n",
    "        else:\n",
    "            for metric in metrics:\n",
    "                data[metric] = ''\n",
    "            for dataset in indices:\n",
    "                for feature in indices[dataset]:\n",
    "                    for approach in approaches:\n",
    "                        sensitive_attributes = indices[dataset][feature]\n",
    "                        for att in sensitive_attributes:\n",
    "                            data_object = DataManager(dataset, feature, approach, objective)\n",
    "                            data_work = data_object.provide_data(objective)\n",
    "                            data_work = data_work\n",
    "                            \n",
    "                            # computing metrics for averaged over each fold\n",
    "                            mean = data_work.mean(axis=0)\n",
    "                            data_metric = {\n",
    "                                'mean': data_work.mean(axis=0),\n",
    "                                'aad': data_work.sub(mean, axis=1).abs().mean(axis=0),\n",
    "                                'mad': data_work.sub(mean, axis=1).abs().max(axis=0),\n",
    "                                'std': data_work.std(axis=0)  \n",
    "                            }\n",
    "                            \n",
    "                            # computing metrics for averaged over each subgroup\n",
    "                            for metric in metrics:\n",
    "                                mean = '%.2f' % (data_metric[metric].mean() * 100)\n",
    "                                std = '%.2f' % (data_metric[metric].std() * 100)\n",
    "                                data.loc[dataset, feature, approach][metric] = f'{mean} ({std})'\n",
    "                        \n",
    "    elif objective == 'predictive_equality' or objective == 'equal_opportunity':\n",
    "        metrics = ['aad', 'mad', 'std']\n",
    "        for metric in metrics:\n",
    "            data[metric] = ''\n",
    "\n",
    "        for dataset in indices:\n",
    "            att = 'att' if dataset == 'bfw' else 'ethnicity'\n",
    "            _, subgroups = DataManager.get_sensitive_attributes_subgroups(dataset) \n",
    "            for feature in indices[dataset]:\n",
    "                for approach in approaches:\n",
    "                    folds_x_subgroups = pd.DataFrame() \n",
    "                    for i, subgroup in enumerate(subgroups[att]):\n",
    "                        data_object = DataManager(dataset, feature, approach, objective, subgroup=subgroup, at_error=global_error)\n",
    "                        folds_x_subgroups[subgroup] = data_object.provide_data(objective)\n",
    "\n",
    "                    # computing metrics for averaged over each subgroup\n",
    "                    mean = folds_x_subgroups.mean(axis=1)\n",
    "                    data_work = {'aad': folds_x_subgroups.sub(mean, axis=0).abs().mean(axis=1),\n",
    "                                 'mad': folds_x_subgroups.sub(mean, axis=0).abs().max(axis=1),\n",
    "                                 'std': folds_x_subgroups.std(axis=1)\n",
    "                                }\n",
    "                    # computing metrics for averaged over each fold\n",
    "                    for metric in metrics:\n",
    "                        mean = '%.2f' % (data_work[metric].mean() * 100)\n",
    "                        std = '%.2f' % (data_work[metric].std() * 100)\n",
    "                        data.loc[dataset, feature, approach][metric] = f'{mean} ({std})'\n",
    "    else:\n",
    "        print('Please specify a valid objective.')\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latex_for(df, objective):\n",
    "    df = df.reset_index()\n",
    "    df = df.pivot(index='approach', columns=['dataset', 'feature']).reorder_levels(['dataset', 'feature', None], axis=1)\n",
    "\n",
    "    good_order = []\n",
    "    for tup in [('rfw', 'facenet'), ('rfw', 'facenet-webface'), ('bfw', 'facenet-webface'), ('bfw', 'arcface')]:\n",
    "        if objective == 'accuracy':\n",
    "            for metric in ['AUROC', 'TPR @ 0.1% FPR', 'TPR @ 1% FPR']: \n",
    "                    good_order.append(tup + (metric,))\n",
    "                    \n",
    "        elif objective == 'fairness_calibration':\n",
    "            for metric in ['mean', 'aad', 'mad', 'std']: \n",
    "                    good_order.append(tup + (metric,))\n",
    "        \n",
    "        elif objective == 'predictive_equality' or objective == 'equal_opportunity':\n",
    "            for metric in ['aad', 'mad', 'std']: \n",
    "                    good_order.append(tup + (metric,)) # also provide information on global fpr or fnr\n",
    "        \n",
    "        else:\n",
    "            print('Please specify a valid objective.')\n",
    "    \n",
    "    df = df[good_order]\n",
    "    return df.to_latex()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Global accuracy measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllllllllllll}\n",
      "\\toprule\n",
      "dataset & \\multicolumn{6}{l}{rfw} & \\multicolumn{6}{l}{bfw} \\\\\n",
      "feature & \\multicolumn{3}{l}{facenet} & \\multicolumn{3}{l}{facenet-webface} & \\multicolumn{3}{l}{facenet-webface} & \\multicolumn{3}{l}{arcface} \\\\\n",
      "{} &         AUROC & TPR @ 0.1\\% FPR &  TPR @ 1\\% FPR &           AUROC & TPR @ 0.1\\% FPR &  TPR @ 1\\% FPR &           AUROC & TPR @ 0.1\\% FPR &  TPR @ 1\\% FPR &         AUROC & TPR @ 0.1\\% FPR &  TPR @ 1\\% FPR \\\\\n",
      "approach &               &                &               &                 &                &               &                 &                &               &               &                &               \\\\\n",
      "\\midrule\n",
      "baseline &  89.97 (0.58) &   25.27 (6.51) &  39.92 (2.40) &    84.46 (0.47) &   11.14 (5.34) &  26.45 (4.90) &    95.17 (0.16) &   30.23 (1.63) &  55.11 (1.25) &  96.82 (0.27) &   87.27 (1.31) &  90.19 (0.87) \\\\\n",
      "faircal  &  92.16 (0.43) &   29.46 (4.65) &  49.95 (4.08) &    86.90 (0.73) &   19.54 (4.38) &  35.05 (4.55) &    96.05 (0.13) &   40.24 (0.26) &  62.59 (0.66) &  97.03 (0.28) &   87.18 (1.40) &  90.15 (0.88) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ns/ywvr68ys7ln1r7pltrqvxv4w0000gn/T/ipykernel_34255/1669770558.py:21: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  return df.to_latex()\n"
     ]
    }
   ],
   "source": [
    "accuracy_table = get_table_for('accuracy')\n",
    "accuracy_in_latex = get_latex_for(accuracy_table, 'accuracy')\n",
    "print(accuracy_in_latex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Fairness Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllllllllllllllll}\n",
      "\\toprule\n",
      "dataset & \\multicolumn{8}{l}{rfw} & \\multicolumn{8}{l}{bfw} \\\\\n",
      "feature & \\multicolumn{4}{l}{facenet} & \\multicolumn{4}{l}{facenet-webface} & \\multicolumn{4}{l}{facenet-webface} & \\multicolumn{4}{l}{arcface} \\\\\n",
      "{} &         mean &          aad &          mad &          std &            mean &          aad &          mad &          std &            mean &          aad &          mad &          std &         mean &          aad &          mad &          std \\\\\n",
      "approach &              &              &              &              &                 &              &              &              &                 &              &              &              &              &              &              &              \\\\\n",
      "\\midrule\n",
      "baseline &  7.28 (3.22) &  0.62 (0.25) &  1.08 (0.31) &  0.79 (0.26) &     7.08 (3.60) &  0.66 (0.05) &  1.54 (0.09) &  0.95 (0.08) &     5.75 (3.29) &  0.91 (0.46) &  1.70 (0.88) &  1.20 (0.59) &  2.86 (1.33) &  0.78 (0.63) &  1.45 (1.10) &  0.99 (0.75) \\\\\n",
      "faircal  &  3.33 (0.49) &  0.62 (0.10) &  1.17 (0.39) &  0.86 (0.16) &     3.82 (0.79) &  0.52 (0.43) &  1.11 (1.06) &  0.74 (0.66) &     3.35 (1.01) &  0.84 (0.35) &  1.46 (0.50) &  1.09 (0.41) &  2.66 (1.16) &  0.71 (0.58) &  1.37 (1.08) &  0.91 (0.72) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ns/ywvr68ys7ln1r7pltrqvxv4w0000gn/T/ipykernel_34255/3566741074.py:23: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  return df.to_latex()\n"
     ]
    }
   ],
   "source": [
    "fairness_cal_table = get_table_for(objective='fairness_calibration', setting='global')\n",
    "from IPython.display import HTML, display\n",
    "HTML(fairness_cal_table.to_html())\n",
    "\n",
    "# fairness_cal_table.loc['rfw', 'facenet']['mean'] = fairness_cal_table.loc['rfw', 'facenet']['mean'].mean()\n",
    "# print(fairness_cal_table)\n",
    "\n",
    "fairness_cal_in_latex = get_latex_for(fairness_cal_table, 'fairness_calibration')\n",
    "print(fairness_cal_in_latex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Predictive Equality ('fpr at fpr') and 4. Equal Opportunity ('fnr at fnr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "equal_opportunity at a global error rate = 0.1%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>aad</th>\n",
       "      <th>mad</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th>feature</th>\n",
       "      <th>approach</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">rfw</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">facenet</th>\n",
       "      <th>baseline</th>\n",
       "      <td>0.14 (0.01)</td>\n",
       "      <td>0.27 (0.02)</td>\n",
       "      <td>0.18 (0.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>faircal</th>\n",
       "      <td>0.13 (0.01)</td>\n",
       "      <td>0.27 (0.03)</td>\n",
       "      <td>0.18 (0.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">facenet-webface</th>\n",
       "      <th>baseline</th>\n",
       "      <td>0.09 (0.03)</td>\n",
       "      <td>0.18 (0.08)</td>\n",
       "      <td>0.12 (0.05)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>faircal</th>\n",
       "      <td>0.13 (0.01)</td>\n",
       "      <td>0.26 (0.02)</td>\n",
       "      <td>0.17 (0.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">bfw</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">facenet-webface</th>\n",
       "      <th>baseline</th>\n",
       "      <td>0.09 (0.02)</td>\n",
       "      <td>0.24 (0.08)</td>\n",
       "      <td>0.12 (0.03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>faircal</th>\n",
       "      <td>0.10 (0.01)</td>\n",
       "      <td>0.27 (0.09)</td>\n",
       "      <td>0.13 (0.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">arcface</th>\n",
       "      <th>baseline</th>\n",
       "      <td>0.10 (0.03)</td>\n",
       "      <td>0.29 (0.15)</td>\n",
       "      <td>0.14 (0.05)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>faircal</th>\n",
       "      <td>0.11 (0.03)</td>\n",
       "      <td>0.36 (0.18)</td>\n",
       "      <td>0.16 (0.06)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "equal_opportunity at a global error rate = 1.0%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>aad</th>\n",
       "      <th>mad</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th>feature</th>\n",
       "      <th>approach</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">rfw</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">facenet</th>\n",
       "      <th>baseline</th>\n",
       "      <td>0.53 (0.13)</td>\n",
       "      <td>0.97 (0.36)</td>\n",
       "      <td>0.72 (0.23)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>faircal</th>\n",
       "      <td>0.37 (0.13)</td>\n",
       "      <td>0.61 (0.22)</td>\n",
       "      <td>0.48 (0.16)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">facenet-webface</th>\n",
       "      <th>baseline</th>\n",
       "      <td>0.44 (0.23)</td>\n",
       "      <td>0.79 (0.51)</td>\n",
       "      <td>0.58 (0.33)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>faircal</th>\n",
       "      <td>0.44 (0.09)</td>\n",
       "      <td>0.81 (0.16)</td>\n",
       "      <td>0.60 (0.11)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">bfw</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">facenet-webface</th>\n",
       "      <th>baseline</th>\n",
       "      <td>0.50 (0.09)</td>\n",
       "      <td>0.98 (0.21)</td>\n",
       "      <td>0.61 (0.11)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>faircal</th>\n",
       "      <td>0.44 (0.16)</td>\n",
       "      <td>0.89 (0.30)</td>\n",
       "      <td>0.55 (0.17)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">arcface</th>\n",
       "      <th>baseline</th>\n",
       "      <td>0.56 (0.22)</td>\n",
       "      <td>1.60 (0.77)</td>\n",
       "      <td>0.79 (0.31)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>faircal</th>\n",
       "      <td>0.74 (0.13)</td>\n",
       "      <td>2.01 (0.73)</td>\n",
       "      <td>1.02 (0.21)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllllllllllll}\n",
      "\\toprule\n",
      "dataset & \\multicolumn{6}{l}{rfw} & \\multicolumn{6}{l}{bfw} \\\\\n",
      "feature & \\multicolumn{3}{l}{facenet} & \\multicolumn{3}{l}{facenet-webface} & \\multicolumn{3}{l}{facenet-webface} & \\multicolumn{3}{l}{arcface} \\\\\n",
      "{} &          aad &          mad &          std &             aad &          mad &          std &             aad &          mad &          std &          aad &          mad &          std \\\\\n",
      "approach &              &              &              &                 &              &              &                 &              &              &              &              &              \\\\\n",
      "\\midrule\n",
      "baseline &  0.53 (0.13) &  0.97 (0.36) &  0.72 (0.23) &     0.44 (0.23) &  0.79 (0.51) &  0.58 (0.33) &     0.50 (0.09) &  0.98 (0.21) &  0.61 (0.11) &  0.56 (0.22) &  1.60 (0.77) &  0.79 (0.31) \\\\\n",
      "faircal  &  0.37 (0.13) &  0.61 (0.22) &  0.48 (0.16) &     0.44 (0.09) &  0.81 (0.16) &  0.60 (0.11) &     0.44 (0.16) &  0.89 (0.30) &  0.55 (0.17) &  0.74 (0.13) &  2.01 (0.73) &  1.02 (0.21) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ns/ywvr68ys7ln1r7pltrqvxv4w0000gn/T/ipykernel_34255/3566741074.py:23: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  return df.to_latex()\n"
     ]
    }
   ],
   "source": [
    "objectives = ['predictive_equality', 'equal_opportunity']\n",
    "global_errors = [1e-3, 1e-2]\n",
    "\n",
    "\n",
    "objectives = ['equal_opportunity']\n",
    "for objective in objectives:\n",
    "    for global_error in global_errors:\n",
    "        current_df = get_table_for(objective, global_error=global_error)\n",
    "        print(f'\\n{objective} at a global error rate = {global_error * 100}%')                \n",
    "        display(HTML(current_df.to_html()))\n",
    "\n",
    "eq_opp_in_latex = get_latex_for(current_df, 'equal_opportunity')\n",
    "print(eq_opp_in_latex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising example results for predictive equality and equal opportunity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example conversion from dataframe to latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "    &         &         &          aad &          mad &          std \\\\\n",
      "dataset & feature & approach &              &              &              \\\\\n",
      "\\midrule\n",
      "rfw & facenet & baseline &  0.53 (0.13) &  0.97 (0.36) &  0.72 (0.23) \\\\\n",
      "    &         & faircal &  0.37 (0.13) &  0.61 (0.22) &  0.48 (0.16) \\\\\n",
      "    & facenet-webface & baseline &  0.44 (0.23) &  0.79 (0.51) &  0.58 (0.33) \\\\\n",
      "    &         & faircal &  0.44 (0.09) &  0.81 (0.16) &  0.60 (0.11) \\\\\n",
      "bfw & facenet-webface & baseline &  0.50 (0.09) &  0.98 (0.21) &  0.61 (0.11) \\\\\n",
      "    &         & faircal &  0.44 (0.16) &  0.89 (0.30) &  0.55 (0.17) \\\\\n",
      "    & arcface & baseline &  0.56 (0.22) &  1.60 (0.77) &  0.79 (0.31) \\\\\n",
      "    &         & faircal &  0.74 (0.13) &  2.01 (0.73) &  1.02 (0.21) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ns/ywvr68ys7ln1r7pltrqvxv4w0000gn/T/ipykernel_34255/957775366.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  txt = current_df.to_latex()\n"
     ]
    }
   ],
   "source": [
    "txt = current_df.to_latex()\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful title/label conversions for latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_approaches = {\n",
    "    'baseline':'Naive',\n",
    "    # 'fsn':'Fair Score',\n",
    "    'faircal':'FairCal (Ours)',\n",
    "    # 'oracle':'Oracle (Ours)'\n",
    "    }\n",
    "title_calibration_methods = {\n",
    "    'beta': 'Beta Calibration'\n",
    "}\n",
    "title_features = {\n",
    "    'facenet':'FaceNet (VGGFace2)',\n",
    "    'facenet-webface':'FaceNet (Webface)',\n",
    "    'arcface': 'ArcFace'}\n",
    "title_metrics = {\n",
    "    'mean': 'Mean',\n",
    "    'aad': 'AAD',\n",
    "    'mad': 'MAD',\n",
    "    'std': 'STD'}\n",
    "caption_metrics = {\n",
    "     'mean': 'Mean',\n",
    "     'aad': 'AAD (Average Absolute Deviation)',\n",
    "     'mad': 'MAD (Maximum Absolute Deviation)',\n",
    "     'std': 'STD (Standard Deviation)',\n",
    "}\n",
    "title_keys = {\n",
    "    'baseline': 'Baseline',\n",
    "    # 'agenda': 'AGENDA',\n",
    "    # 'ftc': 'FTC',\n",
    "    # 'fsn': 'FSN',\n",
    "    'faircal': 'FairCal (Ours)',\n",
    "    # 'oracle': 'Oracle (Ours)'\n",
    "    }\n",
    "header_titles = {\n",
    "    'African': 'Af',\n",
    "    'Asian': 'As',\n",
    "    'Caucasian': 'Ca',\n",
    "    'Indian': 'In',\n",
    "    'asian_females': 'AsF',\n",
    "    'asian_males': 'AsM',\n",
    "    'black_females': 'AfF',\n",
    "    'black_males': 'AfM',\n",
    "    'indian_females': 'IF',\n",
    "    'indian_males': 'IM',\n",
    "    'white_females': 'CF',\n",
    "    'white_males': 'CM',\n",
    "    'Global': 'Gl',\n",
    "    'B': 'Af',\n",
    "    'A': 'As',\n",
    "    'W': 'C',\n",
    "    'I': 'I',\n",
    "    'F': 'F',\n",
    "    'M': 'M'\n",
    "}\n",
    "title_datasets = {\n",
    "    'rfw': 'RFW',\n",
    "    'bfw': 'BFW'\n",
    "}\n",
    "caption_calibration_methods = {\n",
    "    'beta': 'beta calibration'\n",
    "}\n",
    "caption_measures = {\n",
    "    'ks': 'KS'\n",
    "}\n",
    "features_datasets = {\n",
    "    'rfw': ['facenet', 'facenet-webface'],\n",
    "    'bfw': ['facenet-webface']\n",
    "}\n",
    "attributes_datasets = {\n",
    "    'rfw': 'ethnicity',\n",
    "    'bfw': 'att',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot table\n",
    "# pd.pivot_table(df11, values='total', index = ['DateTime2','bid'], columns=['DUID'], aggfunc=np.sum, fill_value=0).reset_index(drop=False)\n",
    "# Melt table (Reverse Pivot)\n",
    "# pd.melt(test, id_vars = ['DateTime2','bid'], value_vars = columns[2:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "38bfd7062c2e40c254718556666e4422f04be01044787720715af94b520c2c5e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
