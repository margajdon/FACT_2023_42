{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tables for FairCal based on Salvador et al., 2022\n",
    "## Reproduced by Group 42 of FACT-AI 2022/23 @ UvA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tables Reproduced\n",
    "\n",
    "1. Global Accuracy Measures\n",
    "2. Fairness Calibration\n",
    "3. Predictive Equality ('fpr at fpr')\n",
    "4. Equal Opportunity ('fnr at fnr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.precision\", 2)\n",
    "import seaborn as sns\n",
    "import sklearn.metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Manager to load pickle files and provide data based on specific table of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataManager():\n",
    "    '''\n",
    "    This class stores the information about the data corresponding to a specific dataset, feature, approach, and objective combination, among other factors.\n",
    "    Input: \n",
    "        dataset (str), e.g. 'rfw'\n",
    "        feature (str), e.g. 'facenet'\n",
    "        approach (str), e.g. 'faircal'\n",
    "        objective (str), e.g. 'accuracy'\n",
    "        ...\n",
    "        \n",
    "    Methods\n",
    "        load_pickle: loads a pickle file into a results dictionary\n",
    "        provide_data: returns a dataframe based on pre-specified objective and other self attributes\n",
    "        get_sensitive_attributes_subgroups: returns a list of sensitive attributes and a dictionary with keys = sensitive attributes and values = subgroups imposed by that attribute\n",
    "\n",
    "    '''\n",
    "    def __init__(self, dataset, feature, approach, objective, calibration_method='beta', n_clusters=100, measure='ks', at_error='1e-2', subgroup='African', fpr_def=[1e-3, 1e-2]):\n",
    "        self.dataset = dataset\n",
    "        self.feature = feature\n",
    "        self.approach = approach\n",
    "        self.objective = objective\n",
    "        self.calibration_method = calibration_method\n",
    "        self.n_clusters = n_clusters\n",
    "        self.measure = measure\n",
    "        self.at_error = at_error\n",
    "        self.subgroup = subgroup\n",
    "        self.fpr_def = fpr_def\n",
    "        self.errors = 'fpr at fpr' if objective == 'predictive_equality' else 'fnr at fnr'\n",
    "        self.nbins = 25 if dataset == 'bfw' else 10\n",
    "        self.att = 'att' if dataset == 'bfw' else 'ethnicity'\n",
    "        self.key = 'calibration' if approach in ['faircal', 'baseline'] else 'pre_calibration'\n",
    "        self.sensitive_attributes, self.subgroups = self.get_sensitive_attributes_subgroups(self.dataset)\n",
    "        self.load_pickle()        \n",
    "\n",
    "    def load_pickle(self):\n",
    "        filename = f'../experiments/{self.dataset}/{self.feature}/{self.approach}/{self.calibration_method}/nbins_{self.nbins}'\n",
    "        if self.approach == 'faircal':\n",
    "            filename += f'_nclusters_{self.n_clusters}'\n",
    "        if self.approach == 'fsn':\n",
    "            filename += f'_nclusters_{n_clusters}_fpr_1e-03'\n",
    "        self.results = np.load(f'{filename}.npy', allow_pickle=True).item()\n",
    "\n",
    "    def provide_data(self, objective):\n",
    "        data = pd.DataFrame()\n",
    "        data['folds'] = ['fold1', 'fold2', 'fold3', 'fold4', 'fold5']\n",
    "        data = data.set_index('folds')\n",
    "        \n",
    "        if self.objective == 'accuracy':\n",
    "            data['AUROC'] = np.nan\n",
    "            data['TPR @ 0.1% FPR'] = np.nan\n",
    "            data['TPR @ 1% FPR'] = np.nan\n",
    "            for fold in range(1,6):\n",
    "                fpr = self.results['fold'+str(fold)]['fpr'][self.att]['Global'][self.key]\n",
    "                tpr = self.results['fold'+str(fold)]['tpr'][self.att]['Global'][self.key]\n",
    "                data.loc[f'fold{str(fold)}', 'AUROC'] = sklearn.metrics.auc(fpr,tpr)\n",
    "                inter = np.interp(self.fpr_def, fpr, tpr)\n",
    "                data.iloc[fold-1, 1:] = inter\n",
    "        \n",
    "        elif self.objective == 'fairness_calibration':\n",
    "            for fold in range(1, 6):\n",
    "                for j, subgroup in enumerate(self.subgroups[self.att]):\n",
    "                    data.loc[f'fold{str(fold)}', f'{subgroup}'] = self.results[f'fold{str(fold)}'][self.measure][self.att][subgroup]\n",
    "      \n",
    "        elif self.objective == 'predictive_equality' or objective == 'equal_opportunity':\n",
    "            data[self.at_error] = np.nan\n",
    "            \n",
    "            for fold in range(1,6):\n",
    "                if self.subgroup == 'Global':\n",
    "                    data.iloc[fold-1,:] = self.at_error\n",
    "                else:\n",
    "                    fpr_global = self.results['fold'+str(fold)]['fpr'][self.att]['Global'][self.key]\n",
    "                    tpr_global = self.results['fold'+str(fold)]['tpr'][self.att]['Global'][self.key]\n",
    "                    thr_global = np.fmin(self.results['fold'+str(fold)]['thresholds'][self.att]['Global'][self.key], 1)\n",
    "\n",
    "                    fpr = self.results['fold'+str(fold)]['fpr'][self.att][self.subgroup][self.key]\n",
    "                    tpr = self.results['fold'+str(fold)]['tpr'][self.att][self.subgroup][self.key]\n",
    "                    thr = np.fmin(self.results['fold'+str(fold)]['thresholds'][self.att][self.subgroup][self.key], 1)\n",
    "\n",
    "                    if self.errors == 'fpr at fpr':\n",
    "                        thr_at_error = np.interp(self.at_error,fpr_global,thr_global)\n",
    "                        data.iloc[fold-1,:] = np.interp(thr_at_error,thr[::-1],fpr[::-1])\n",
    "                    elif self.errors == 'fnr at fnr':\n",
    "                        thr_at_error = np.interp(1-np.array(self.at_error),tpr_global,thr_global)\n",
    "                        data.iloc[fold-1,:] = 1-np.interp(thr_at_error,thr[::-1],tpr[::-1])  \n",
    "        else:\n",
    "            print('Please specify a valid objective.')\n",
    "        return data\n",
    "\n",
    "    @staticmethod\n",
    "    def get_sensitive_attributes_subgroups(dataset):\n",
    "        '''\n",
    "        A helper function to get sensitive attributes per subgroup, depending on the dataset.\n",
    "        \n",
    "        '''\n",
    "        if dataset == 'rfw':\n",
    "            sensitive_attributes = ['ethnicity']\n",
    "            subgroups = {'ethnicity':['African', 'Asian', 'Caucasian', 'Indian']}\n",
    "        else:\n",
    "            sensitive_attributes = ['e', 'g', 'att']\n",
    "            subgroups = {\n",
    "                'e':['B', 'A', 'W', 'I'],\n",
    "                'g':['F','M'],\n",
    "                'att': ['black_females', 'black_males', 'asian_females', 'asian_males', 'white_females', 'white_males', 'indian_females', 'indian_males']\n",
    "            }\n",
    "        return sensitive_attributes, subgroups\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A general multi-index table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multi_table(objective):\n",
    "    approaches = ['baseline', 'faircal']\n",
    "    tuples = []\n",
    "    \n",
    "    if objective == 'fairness_calibration':\n",
    "        indices = {\n",
    "        'rfw' : {\n",
    "            'facenet': ['African', 'Asian', 'Caucasian', 'Indian'],\n",
    "            'facenet-webface': ['African', 'Asian', 'Caucasian', 'Indian'],\n",
    "        },\n",
    "        'bfw' : {\n",
    "            'facenet-webface': ['B', 'A', 'W', 'I', 'F','M', \n",
    "                'black_females', 'black_males', 'asian_females', 'asian_males', 'white_females', 'white_males', 'indian_females', 'indian_males'],\n",
    "            'arcface': ['B', 'A', 'W', 'I', 'F','M', \n",
    "                'black_females', 'black_males', 'asian_females', 'asian_males', 'white_females', 'white_males', 'indian_females', 'indian_males'],\n",
    "            },\n",
    "        }\n",
    "        for dataset in indices:\n",
    "            for feature, sens in indices[dataset].items():\n",
    "                for att in sens:\n",
    "                    for approach in approaches:\n",
    "                        tuples.append((dataset, feature, att, approach))\n",
    "        index = pd.MultiIndex.from_tuples(tuples, names=['dataset', 'feature', 'subgroup', 'approach'])\n",
    "    \n",
    "    else:\n",
    "        indices = {\n",
    "        'rfw' : ['facenet', 'facenet-webface'],\n",
    "        'bfw' : ['facenet-webface', 'arcface']\n",
    "        }\n",
    "        for dataset in indices:\n",
    "            for feature in indices[dataset]:\n",
    "                for approach in approaches:\n",
    "                    tuples.append((dataset, feature, approach))\n",
    "        index = pd.MultiIndex.from_tuples(tuples, names=['dataset', 'feature', 'approach'])\n",
    "    \n",
    "    data = pd.DataFrame(index=index)\n",
    "    return approaches, indices, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_for(objective, global_error=1e-2):\n",
    "    approaches, indices, data = create_multi_table(objective)\n",
    "\n",
    "    if objective == 'accuracy':\n",
    "        metrics = ['AUROC', 'TPR @ 0.1% FPR', 'TPR @ 1% FPR']\n",
    "        for metric in metrics:\n",
    "            data[metric] = ''\n",
    "        error = [1e-3, 1e-2]\n",
    "    \n",
    "        for dataset in indices:\n",
    "            for feature in indices[dataset]:\n",
    "                for approach in approaches:\n",
    "                    data_object = DataManager(dataset, feature, approach, objective, fpr_def=error)\n",
    "                    data_work = data_object.provide_data(objective)\n",
    "                    data_work *= 100\n",
    "                    for metric in metrics:\n",
    "                        mean = '%.2f' % data_work[metric].mean()\n",
    "                        std = '%.2f' % data_work[metric].std()\n",
    "                        data.loc[dataset, feature, approach][metric] = f'{str(mean)} ({str(std)})'\n",
    "    \n",
    "    elif objective == 'fairness_calibration':\n",
    "        metrics = ['mean', 'aad', 'mad', 'std']\n",
    "        for metric in metrics:\n",
    "            data[metric] = np.nan\n",
    "\n",
    "        for dataset in indices:\n",
    "            for feature in indices[dataset]:\n",
    "                for approach in approaches:\n",
    "                    sensitive_attributes = indices[dataset][feature]\n",
    "                    for att in sensitive_attributes:\n",
    "                        data_object = DataManager(dataset, feature, approach, objective)\n",
    "                        data_work = data_object.provide_data(objective)\n",
    "                        data_work = data_work * 100\n",
    "                        for subgroup in data_work.columns:\n",
    "                            group_mean = data_work[subgroup].mean()\n",
    "                            data.loc[dataset, feature, subgroup, approach]['mean'] = group_mean\n",
    "                            data.loc[dataset, feature, subgroup, approach]['aad'] = np.abs(data_work[subgroup] - group_mean).mean()\n",
    "                            data.loc[dataset, feature, subgroup, approach]['mad'] = np.abs(data_work[subgroup] - group_mean).max()\n",
    "                            data.loc[dataset, feature, subgroup, approach]['std'] = np.std(data_work[subgroup])\n",
    "    \n",
    "    elif objective == 'predictive_equality' or objective == 'equal_opportunity':\n",
    "        metrics = ['aad', 'mad', 'std']\n",
    "        for metric in metrics:\n",
    "            data[metric] = ''\n",
    "\n",
    "        for dataset in indices:\n",
    "            att = 'att' if dataset == 'bfw' else 'ethnicity'\n",
    "            _, subgroups = DataManager.get_sensitive_attributes_subgroups(dataset) \n",
    "            for feature in indices[dataset]:\n",
    "                for approach in approaches:\n",
    "                    folds_x_subgroups = pd.DataFrame() \n",
    "                    for i, subgroup in enumerate(subgroups[att]):\n",
    "                        data_object = DataManager(dataset, feature, approach, objective, subgroup=subgroup, at_error=global_error)\n",
    "                        folds_x_subgroups[subgroup] = data_object.provide_data(objective)\n",
    "\n",
    "                    # computing metrics for averaged over each subgroup\n",
    "                    mean = folds_x_subgroups.mean(axis=1)\n",
    "                    data_work = {'aad': folds_x_subgroups.sub(mean, axis=0).abs().mean(axis=1),\n",
    "                                 'mad': folds_x_subgroups.sub(mean, axis=0).abs().max(axis=1),\n",
    "                                 'std': folds_x_subgroups.std(axis=1)\n",
    "                                }\n",
    "\n",
    "                    for metric in metrics:\n",
    "                        mean = '%.2f' % (data_work[metric].mean() * 100)\n",
    "                        std = '%.2f' % (data_work[metric].std() * 100)\n",
    "                        data.loc[dataset, feature, approach][metric] = f'{mean} ({std})'\n",
    "    else:\n",
    "        print('Please specify a valid objective.')\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Global accuracy measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         AUROC TPR @ 0.1% FPR  TPR @ 1% FPR\n",
      "dataset feature         approach                                           \n",
      "rfw     facenet         baseline  89.97 (0.58)   25.27 (6.51)  39.92 (2.40)\n",
      "                        faircal   92.16 (0.43)   29.46 (4.65)  49.95 (4.08)\n",
      "        facenet-webface baseline  84.46 (0.47)   11.14 (5.34)  26.45 (4.90)\n",
      "                        faircal   86.90 (0.73)   19.54 (4.38)  35.05 (4.55)\n",
      "bfw     facenet-webface baseline  95.17 (0.16)   30.23 (1.63)  55.11 (1.25)\n",
      "                        faircal   96.05 (0.13)   40.24 (0.26)  62.59 (0.66)\n",
      "        arcface         baseline  96.82 (0.27)   87.27 (1.31)  90.19 (0.87)\n",
      "                        faircal   97.03 (0.28)   87.18 (1.40)  90.15 (0.88)\n"
     ]
    }
   ],
   "source": [
    "accuracy_table = get_table_for('accuracy')\n",
    "print(accuracy_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Fairness Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          mean   aad   mad   std\n",
      "dataset feature subgroup       approach                         \n",
      "rfw     facenet African        baseline   6.29  0.56  1.00  0.61\n",
      "                               faircal    1.72  0.50  0.73  0.55\n",
      "                Asian          baseline   5.66  0.40  0.63  0.43\n",
      "                               faircal    1.70  0.48  0.86  0.56\n",
      "                Caucasian      baseline  11.22  0.85  1.09  0.91\n",
      "...                                        ...   ...   ...   ...\n",
      "bfw     arcface white_males    faircal    0.89  0.31  0.63  0.37\n",
      "                indian_females baseline   2.27  0.42  0.98  0.54\n",
      "                               faircal    2.10  0.43  0.76  0.47\n",
      "                indian_males   baseline   2.17  0.96  1.27  0.99\n",
      "                               faircal    2.10  0.89  1.35  0.95\n",
      "\n",
      "[72 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "fairness_cal_table = get_table_for('fairness_calibration')\n",
    "print(fairness_cal_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Predictive Equality ('fpr at fpr') and 4. Equal Opportunity ('fnr at fnr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "predictive_equality at a global error rate = 0.1%\n",
      "                                          aad          mad          std\n",
      "dataset feature         approach                                       \n",
      "rfw     facenet         baseline  0.17 (0.06)  0.31 (0.13)  0.22 (0.08)\n",
      "                        faircal   0.20 (0.03)  0.38 (0.12)  0.26 (0.05)\n",
      "        facenet-webface baseline  0.14 (0.03)  0.27 (0.07)  0.19 (0.04)\n",
      "                        faircal   0.14 (0.02)  0.20 (0.03)  0.17 (0.01)\n",
      "bfw     facenet-webface baseline  0.29 (0.09)  0.98 (0.43)  0.42 (0.16)\n",
      "                        faircal   0.09 (0.03)  0.16 (0.06)  0.11 (0.04)\n",
      "        arcface         baseline  0.14 (0.02)  0.31 (0.15)  0.18 (0.04)\n",
      "                        faircal   0.14 (0.03)  0.32 (0.17)  0.18 (0.05)\n",
      "\n",
      "predictive_equality at a global error rate = 1.0%\n",
      "                                          aad          mad          std\n",
      "dataset feature         approach                                       \n",
      "rfw     facenet         baseline  0.74 (0.10)  0.94 (0.16)  0.90 (0.10)\n",
      "                        faircal   0.44 (0.25)  0.81 (0.51)  0.61 (0.32)\n",
      "        facenet-webface baseline  0.68 (0.23)  1.21 (0.44)  0.91 (0.28)\n",
      "                        faircal   0.37 (0.12)  0.69 (0.25)  0.53 (0.16)\n",
      "bfw     facenet-webface baseline  2.11 (0.20)  6.68 (1.84)  3.03 (0.58)\n",
      "                        faircal   0.63 (0.12)  1.57 (0.65)  0.84 (0.19)\n",
      "        arcface         baseline  0.82 (0.22)  1.59 (0.33)  1.02 (0.23)\n",
      "                        faircal   0.76 (0.22)  1.52 (0.36)  0.98 (0.24)\n",
      "\n",
      "equal_opportunity at a global error rate = 0.1%\n",
      "                                          aad          mad          std\n",
      "dataset feature         approach                                       \n",
      "rfw     facenet         baseline  0.14 (0.01)  0.27 (0.02)  0.18 (0.02)\n",
      "                        faircal   0.13 (0.01)  0.27 (0.03)  0.18 (0.02)\n",
      "        facenet-webface baseline  0.09 (0.03)  0.18 (0.08)  0.12 (0.05)\n",
      "                        faircal   0.13 (0.01)  0.26 (0.02)  0.17 (0.02)\n",
      "bfw     facenet-webface baseline  0.09 (0.02)  0.24 (0.08)  0.12 (0.03)\n",
      "                        faircal   0.10 (0.01)  0.27 (0.09)  0.13 (0.02)\n",
      "        arcface         baseline  0.10 (0.03)  0.29 (0.15)  0.14 (0.05)\n",
      "                        faircal   0.11 (0.03)  0.36 (0.18)  0.16 (0.06)\n",
      "\n",
      "equal_opportunity at a global error rate = 1.0%\n",
      "                                          aad          mad          std\n",
      "dataset feature         approach                                       \n",
      "rfw     facenet         baseline  0.53 (0.13)  0.97 (0.36)  0.72 (0.23)\n",
      "                        faircal   0.37 (0.13)  0.61 (0.22)  0.48 (0.16)\n",
      "        facenet-webface baseline  0.44 (0.23)  0.79 (0.51)  0.58 (0.33)\n",
      "                        faircal   0.44 (0.09)  0.81 (0.16)  0.60 (0.11)\n",
      "bfw     facenet-webface baseline  0.50 (0.09)  0.98 (0.21)  0.61 (0.11)\n",
      "                        faircal   0.44 (0.16)  0.89 (0.30)  0.55 (0.17)\n",
      "        arcface         baseline  0.56 (0.22)  1.60 (0.77)  0.79 (0.31)\n",
      "                        faircal   0.74 (0.13)  2.01 (0.73)  1.02 (0.21)\n"
     ]
    }
   ],
   "source": [
    "objectives = ['predictive_equality', 'equal_opportunity']\n",
    "global_errors = [1e-3, 1e-2]\n",
    "\n",
    "for objective in objectives:\n",
    "    for global_error in global_errors:\n",
    "        current_df = get_table_for(objective, global_error=global_error)\n",
    "        print(f'\\n{objective} at a global error rate = {global_error * 100}%')                \n",
    "        print(current_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising example results for predictive equality and equal opportunity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example conversion from dataframe to latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "    &         &         &          aad &          mad &          std \\\\\n",
      "dataset & feature & approach &              &              &              \\\\\n",
      "\\midrule\n",
      "rfw & facenet & baseline &  0.53 (0.13) &  0.97 (0.36) &  0.72 (0.23) \\\\\n",
      "    &         & faircal &  0.37 (0.13) &  0.61 (0.22) &  0.48 (0.16) \\\\\n",
      "    & facenet-webface & baseline &  0.44 (0.23) &  0.79 (0.51) &  0.58 (0.33) \\\\\n",
      "    &         & faircal &  0.44 (0.09) &  0.81 (0.16) &  0.60 (0.11) \\\\\n",
      "bfw & facenet-webface & baseline &  0.50 (0.09) &  0.98 (0.21) &  0.61 (0.11) \\\\\n",
      "    &         & faircal &  0.44 (0.16) &  0.89 (0.30) &  0.55 (0.17) \\\\\n",
      "    & arcface & baseline &  0.56 (0.22) &  1.60 (0.77) &  0.79 (0.31) \\\\\n",
      "    &         & faircal &  0.74 (0.13) &  2.01 (0.73) &  1.02 (0.21) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ns/ywvr68ys7ln1r7pltrqvxv4w0000gn/T/ipykernel_40434/957775366.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  txt = current_df.to_latex()\n"
     ]
    }
   ],
   "source": [
    "txt = current_df.to_latex()\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful title/label conversions for latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_approaches = {\n",
    "    'baseline':'Naive',\n",
    "    # 'fsn':'Fair Score',\n",
    "    'faircal':'FairCal (Ours)',\n",
    "    # 'oracle':'Oracle (Ours)'\n",
    "    }\n",
    "title_calibration_methods = {\n",
    "    'beta': 'Beta Calibration'\n",
    "}\n",
    "title_features = {\n",
    "    'facenet':'FaceNet (VGGFace2)',\n",
    "    'facenet-webface':'FaceNet (Webface)',\n",
    "    'arcface': 'ArcFace'}\n",
    "title_metrics = {\n",
    "    'mean': 'Mean',\n",
    "    'aad': 'AAD',\n",
    "    'mad': 'MAD',\n",
    "    'std': 'STD'}\n",
    "caption_metrics = {\n",
    "     'mean': 'Mean',\n",
    "     'aad': 'AAD (Average Absolute Deviation)',\n",
    "     'mad': 'MAD (Maximum Absolute Deviation)',\n",
    "     'std': 'STD (Standard Deviation)',\n",
    "}\n",
    "title_keys = {\n",
    "    'baseline': 'Baseline',\n",
    "    # 'agenda': 'AGENDA',\n",
    "    # 'ftc': 'FTC',\n",
    "    # 'fsn': 'FSN',\n",
    "    'faircal': 'FairCal (Ours)',\n",
    "    # 'oracle': 'Oracle (Ours)'\n",
    "    }\n",
    "header_titles = {\n",
    "    'African': 'Af',\n",
    "    'Asian': 'As',\n",
    "    'Caucasian': 'Ca',\n",
    "    'Indian': 'In',\n",
    "    'asian_females': 'AsF',\n",
    "    'asian_males': 'AsM',\n",
    "    'black_females': 'AfF',\n",
    "    'black_males': 'AfM',\n",
    "    'indian_females': 'IF',\n",
    "    'indian_males': 'IM',\n",
    "    'white_females': 'CF',\n",
    "    'white_males': 'CM',\n",
    "    'Global': 'Gl',\n",
    "    'B': 'Af',\n",
    "    'A': 'As',\n",
    "    'W': 'C',\n",
    "    'I': 'I',\n",
    "    'F': 'F',\n",
    "    'M': 'M'\n",
    "}\n",
    "title_datasets = {\n",
    "    'rfw': 'RFW',\n",
    "    'bfw': 'BFW'\n",
    "}\n",
    "caption_calibration_methods = {\n",
    "    'beta': 'beta calibration'\n",
    "}\n",
    "caption_measures = {\n",
    "    'ks': 'KS'\n",
    "}\n",
    "features_datasets = {\n",
    "    'rfw': ['facenet', 'facenet-webface'],\n",
    "    'bfw': ['facenet-webface']\n",
    "}\n",
    "attributes_datasets = {\n",
    "    'rfw': 'ethnicity',\n",
    "    'bfw': 'att',\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "38bfd7062c2e40c254718556666e4422f04be01044787720715af94b520c2c5e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
