{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3d18cc3",
   "metadata": {},
   "source": [
    "# Figures for FairCal based on Salvador et al., 2022\n",
    "## Reproduced by Group 42 of FACT-AI 2022/23 @ UvA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f784f49",
   "metadata": {},
   "source": [
    "### Figures Reproduced\n",
    "\n",
    "1. Violin plots (Distribution of cosine similarity scores for genuine and imposter pairs, by subgroup)\n",
    "2. Fairness plots (Global FPR vs Subgroup-specific FPR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb06aee",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56022ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cvxpy in /Users/milenakapralova/opt/anaconda3/envs/progLab/lib/python3.9/site-packages (1.3.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /Users/milenakapralova/opt/anaconda3/envs/progLab/lib/python3.9/site-packages (from cvxpy) (1.9.1)\n",
      "Requirement already satisfied: osqp>=0.4.1 in /Users/milenakapralova/opt/anaconda3/envs/progLab/lib/python3.9/site-packages (from cvxpy) (0.6.2.post8)\n",
      "Requirement already satisfied: setuptools<=64.0.2 in /Users/milenakapralova/opt/anaconda3/envs/progLab/lib/python3.9/site-packages (from cvxpy) (64.0.2)\n",
      "Requirement already satisfied: ecos>=2 in /Users/milenakapralova/opt/anaconda3/envs/progLab/lib/python3.9/site-packages (from cvxpy) (2.0.12)\n",
      "Requirement already satisfied: scs>=1.1.6 in /Users/milenakapralova/opt/anaconda3/envs/progLab/lib/python3.9/site-packages (from cvxpy) (3.2.2)\n",
      "Requirement already satisfied: numpy>=1.15 in /Users/milenakapralova/opt/anaconda3/envs/progLab/lib/python3.9/site-packages (from cvxpy) (1.23.1)\n",
      "Requirement already satisfied: qdldl in /Users/milenakapralova/opt/anaconda3/envs/progLab/lib/python3.9/site-packages (from osqp>=0.4.1->cvxpy) (0.1.5.post3)\n"
     ]
    }
   ],
   "source": [
    "!pip install cvxpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "845bddf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "from approaches import baseline, cluster_methods, oracle\n",
    "from approaches_ftc import ftc\n",
    "from approaches_agenda import agenda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd93b79",
   "metadata": {},
   "source": [
    "### Plotting-specific settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "packed-parking",
   "metadata": {},
   "outputs": [],
   "source": [
    "legend_fontsize = 14\n",
    "title_fontsize = 18\n",
    "label_fontsize = 16\n",
    "ticks_fontsize = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cb4f30",
   "metadata": {},
   "source": [
    "### Loading cosine similarities (settings: rfw, facenet-webface, beta calibration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "boxed-redhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pd.read_csv('data/rfw/rfw_w_sims.csv')\n",
    "dataset_name = 'rfw'\n",
    "feature = 'facenet'\n",
    "calibration_method = 'beta'\n",
    "nbins = 25\n",
    "n_clusters = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d11dd45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.2</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id1</th>\n",
       "      <th>num1</th>\n",
       "      <th>id2</th>\n",
       "      <th>num2</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>pair</th>\n",
       "      <th>same</th>\n",
       "      <th>fold</th>\n",
       "      <th>facenet</th>\n",
       "      <th>facenet-webface</th>\n",
       "      <th>arcface</th>\n",
       "      <th>image_id_1_clean</th>\n",
       "      <th>image_id_2_clean</th>\n",
       "      <th>unique_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>m.0g5ty_</td>\n",
       "      <td>1</td>\n",
       "      <td>m.0g5ty_</td>\n",
       "      <td>2</td>\n",
       "      <td>African</td>\n",
       "      <td>Genuine</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.733062</td>\n",
       "      <td>0.610138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m.0g5ty__1</td>\n",
       "      <td>m.0g5ty__2</td>\n",
       "      <td>m.0g5ty__1_m.0g5ty__2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>m.05q5bqf</td>\n",
       "      <td>2</td>\n",
       "      <td>m.05q5bqf</td>\n",
       "      <td>3</td>\n",
       "      <td>African</td>\n",
       "      <td>Genuine</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.656041</td>\n",
       "      <td>0.536733</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m.05q5bqf_2</td>\n",
       "      <td>m.05q5bqf_3</td>\n",
       "      <td>m.05q5bqf_2_m.05q5bqf_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>m.03yfnz5</td>\n",
       "      <td>2</td>\n",
       "      <td>m.03yfnz5</td>\n",
       "      <td>1</td>\n",
       "      <td>African</td>\n",
       "      <td>Genuine</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.624838</td>\n",
       "      <td>0.631015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m.03yfnz5_2</td>\n",
       "      <td>m.03yfnz5_1</td>\n",
       "      <td>m.03yfnz5_2_m.03yfnz5_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>m.03npynb</td>\n",
       "      <td>2</td>\n",
       "      <td>m.03npynb</td>\n",
       "      <td>3</td>\n",
       "      <td>African</td>\n",
       "      <td>Genuine</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.635635</td>\n",
       "      <td>0.593042</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m.03npynb_2</td>\n",
       "      <td>m.03npynb_3</td>\n",
       "      <td>m.03npynb_2_m.03npynb_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>m.0h1f_hh</td>\n",
       "      <td>1</td>\n",
       "      <td>m.0h1f_hh</td>\n",
       "      <td>3</td>\n",
       "      <td>African</td>\n",
       "      <td>Genuine</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.788073</td>\n",
       "      <td>0.695494</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m.0h1f_hh_1</td>\n",
       "      <td>m.0h1f_hh_3</td>\n",
       "      <td>m.0h1f_hh_1_m.0h1f_hh_3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.2  Unnamed: 0.1  Unnamed: 0        id1  num1        id2  num2  \\\n",
       "0             0             0           0   m.0g5ty_     1   m.0g5ty_     2   \n",
       "1             1             1           1  m.05q5bqf     2  m.05q5bqf     3   \n",
       "2             2             2           2  m.03yfnz5     2  m.03yfnz5     1   \n",
       "3             3             3           3  m.03npynb     2  m.03npynb     3   \n",
       "4             4             4           4  m.0h1f_hh     1  m.0h1f_hh     3   \n",
       "\n",
       "  ethnicity     pair  same  fold   facenet  facenet-webface  arcface  \\\n",
       "0   African  Genuine  True     0  0.733062         0.610138      NaN   \n",
       "1   African  Genuine  True     0  0.656041         0.536733      NaN   \n",
       "2   African  Genuine  True     0  0.624838         0.631015      NaN   \n",
       "3   African  Genuine  True     0  0.635635         0.593042      NaN   \n",
       "4   African  Genuine  True     0  0.788073         0.695494      NaN   \n",
       "\n",
       "  image_id_1_clean image_id_2_clean               unique_key  \n",
       "0       m.0g5ty__1       m.0g5ty__2    m.0g5ty__1_m.0g5ty__2  \n",
       "1      m.05q5bqf_2      m.05q5bqf_3  m.05q5bqf_2_m.05q5bqf_3  \n",
       "2      m.03yfnz5_2      m.03yfnz5_1  m.03yfnz5_2_m.03yfnz5_1  \n",
       "3      m.03npynb_2      m.03npynb_3  m.03npynb_2_m.03npynb_3  \n",
       "4      m.0h1f_hh_1      m.0h1f_hh_3  m.0h1f_hh_1_m.0h1f_hh_3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(db.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "african-pledge",
   "metadata": {},
   "outputs": [],
   "source": [
    "subgroups = {'ethnicity': ['African', 'Asian', 'Caucasian', 'Indian']}\n",
    "sensitive_attributes = {'ethnicity': ['ethnicity', 'ethnicity']}\n",
    "fold = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "quality-lyric",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['facenet-webface']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "continuing-wisconsin",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_features = {\n",
    "    'facenet':'FaceNet (VGGFace2)',\n",
    "    'facenet-webface':'FaceNet (Webface)',\n",
    "    'arcface': 'ArcFace'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "surrounded-receptor",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_methods = {\n",
    "    'naive': 'Baseline',\n",
    "    'faircal': 'Faircal (Ours)'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "backed-jacket",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_fold = {'cal': db[db['fold'] != fold], 'test': db[db['fold'] == fold]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a0b0c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cal':        Unnamed: 0.2  Unnamed: 0.1  Unnamed: 0        id1  num1        id2  \\\n",
      "0                 0             0           0   m.0g5ty_     1   m.0g5ty_   \n",
      "1                 1             1           1  m.05q5bqf     2  m.05q5bqf   \n",
      "2                 2             2           2  m.03yfnz5     2  m.03yfnz5   \n",
      "3                 3             3           3  m.03npynb     2  m.03npynb   \n",
      "4                 4             4           4  m.0h1f_hh     1  m.0h1f_hh   \n",
      "...             ...           ...         ...        ...   ...        ...   \n",
      "23989         23995         23995       23995  m.0gb_yjt     2  m.05p6bss   \n",
      "23990         23996         23996       23996   m.01qhc8     1  m.01wv0z3   \n",
      "23991         23997         23997       23997   m.03w3mt     2  m.02qgh9z   \n",
      "23992         23998         23998       23998   m.0674cw     4  m.09rv9x_   \n",
      "23993         23999         23999       23999   m.03zd_s     2   m.070pyk   \n",
      "\n",
      "       num2 ethnicity       pair   same  fold   facenet  facenet-webface  \\\n",
      "0         2   African    Genuine   True     0  0.733062         0.610138   \n",
      "1         3   African    Genuine   True     0  0.656041         0.536733   \n",
      "2         1   African    Genuine   True     0  0.624838         0.631015   \n",
      "3         3   African    Genuine   True     0  0.635635         0.593042   \n",
      "4         3   African    Genuine   True     0  0.788073         0.695494   \n",
      "...     ...       ...        ...    ...   ...       ...              ...   \n",
      "23989     1    Indian  Ungenuine  False     9  0.273669         0.258845   \n",
      "23990     2    Indian  Ungenuine  False     9  0.430417         0.450921   \n",
      "23991     3    Indian  Ungenuine  False     9  0.517445         0.344384   \n",
      "23992     1    Indian  Ungenuine  False     9  0.215046         0.248212   \n",
      "23993     1    Indian  Ungenuine  False     9  0.411868         0.245868   \n",
      "\n",
      "       arcface image_id_1_clean image_id_2_clean               unique_key  \n",
      "0          NaN       m.0g5ty__1       m.0g5ty__2    m.0g5ty__1_m.0g5ty__2  \n",
      "1          NaN      m.05q5bqf_2      m.05q5bqf_3  m.05q5bqf_2_m.05q5bqf_3  \n",
      "2          NaN      m.03yfnz5_2      m.03yfnz5_1  m.03yfnz5_2_m.03yfnz5_1  \n",
      "3          NaN      m.03npynb_2      m.03npynb_3  m.03npynb_2_m.03npynb_3  \n",
      "4          NaN      m.0h1f_hh_1      m.0h1f_hh_3  m.0h1f_hh_1_m.0h1f_hh_3  \n",
      "...        ...              ...              ...                      ...  \n",
      "23989      NaN      m.0gb_yjt_2      m.05p6bss_1  m.0gb_yjt_2_m.05p6bss_1  \n",
      "23990      NaN       m.01qhc8_1      m.01wv0z3_2   m.01qhc8_1_m.01wv0z3_2  \n",
      "23991      NaN       m.03w3mt_2      m.02qgh9z_3   m.03w3mt_2_m.02qgh9z_3  \n",
      "23992      NaN       m.0674cw_4      m.09rv9x__1   m.0674cw_4_m.09rv9x__1  \n",
      "23993      NaN       m.03zd_s_2       m.070pyk_1    m.03zd_s_2_m.070pyk_1  \n",
      "\n",
      "[21596 rows x 17 columns], 'test':        Unnamed: 0.2  Unnamed: 0.1  Unnamed: 0        id1  num1        id2  \\\n",
      "2998           3000          3000        3000   m.0bwh6b     3   m.0bwh6b   \n",
      "2999           3001          3001        3001  m.01wf_f3     1  m.01wf_f3   \n",
      "3000           3002          3002        3002  m.03f7dxh     3  m.03f7dxh   \n",
      "3001           3003          3003        3003   m.04rlb8     3   m.04rlb8   \n",
      "3002           3004          3004        3004   m.0c7nfp     2   m.0c7nfp   \n",
      "...             ...           ...         ...        ...   ...        ...   \n",
      "21589         21595         21595       21595    m.0krsd     3  m.04jfczz   \n",
      "21590         21596         21596       21596  m.027bp7c     3   m.0744sc   \n",
      "21591         21597         21597       21597  m.04yb7nl     1   m.02s6mz   \n",
      "21592         21598         21598       21598  m.02qhg7v     2  m.0gf8pjf   \n",
      "21593         21599         21599       21599  m.0gc950n     1  m.0n9mwwx   \n",
      "\n",
      "       num2 ethnicity       pair   same  fold   facenet  facenet-webface  \\\n",
      "2998      1   African    Genuine   True     5  0.493242         0.422751   \n",
      "2999      2   African    Genuine   True     5  0.590028         0.393036   \n",
      "3000      1   African    Genuine   True     5  0.761648         0.609428   \n",
      "3001      2   African    Genuine   True     5  0.569876         0.434694   \n",
      "3002      1   African    Genuine   True     5  0.489396         0.557251   \n",
      "...     ...       ...        ...    ...   ...       ...              ...   \n",
      "21589     3    Indian  Ungenuine  False     5  0.454975         0.394362   \n",
      "21590     2    Indian  Ungenuine  False     5  0.255344         0.269877   \n",
      "21591     4    Indian  Ungenuine  False     5  0.503230         0.402199   \n",
      "21592     4    Indian  Ungenuine  False     5  0.208550         0.371668   \n",
      "21593     1    Indian  Ungenuine  False     5  0.228692         0.065384   \n",
      "\n",
      "       arcface image_id_1_clean image_id_2_clean               unique_key  \n",
      "2998       NaN       m.0bwh6b_3       m.0bwh6b_1    m.0bwh6b_3_m.0bwh6b_1  \n",
      "2999       NaN      m.01wf_f3_1      m.01wf_f3_2  m.01wf_f3_1_m.01wf_f3_2  \n",
      "3000       NaN      m.03f7dxh_3      m.03f7dxh_1  m.03f7dxh_3_m.03f7dxh_1  \n",
      "3001       NaN       m.04rlb8_3       m.04rlb8_2    m.04rlb8_3_m.04rlb8_2  \n",
      "3002       NaN       m.0c7nfp_2       m.0c7nfp_1    m.0c7nfp_2_m.0c7nfp_1  \n",
      "...        ...              ...              ...                      ...  \n",
      "21589      NaN        m.0krsd_3      m.04jfczz_3    m.0krsd_3_m.04jfczz_3  \n",
      "21590      NaN      m.027bp7c_3       m.0744sc_2   m.027bp7c_3_m.0744sc_2  \n",
      "21591      NaN      m.04yb7nl_1       m.02s6mz_4   m.04yb7nl_1_m.02s6mz_4  \n",
      "21592      NaN      m.02qhg7v_2      m.0gf8pjf_4  m.02qhg7v_2_m.0gf8pjf_4  \n",
      "21593      NaN      m.0gc950n_1      m.0n9mwwx_1  m.0gc950n_1_m.0n9mwwx_1  \n",
      "\n",
      "[2398 rows x 17 columns]}\n"
     ]
    }
   ],
   "source": [
    "print(db_fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bdbe62",
   "metadata": {},
   "source": [
    "### Getting dictionaries for cosine similarities (float), confidence scores (empty), ground truth labels (boolean) and subgroup scores (ethnicity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "invalid-stephen",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "confidences = {}\n",
    "for feature in features:\n",
    "    scores[feature] = {}\n",
    "    confidences[feature] = {}\n",
    "ground_truth = {}\n",
    "subgroup_scores = {}\n",
    "for dataset in ['cal', 'test']:\n",
    "    for feature in features:\n",
    "        scores[feature][dataset] = np.array(db_fold[dataset][feature])\n",
    "    ground_truth[dataset] = np.array(db_fold[dataset]['same'])\n",
    "    subgroup_scores[dataset] = {}\n",
    "    for att in subgroups.keys():\n",
    "        subgroup_scores[dataset][att] = {}\n",
    "        subgroup_scores[dataset][att]['left'] = np.array(db_fold[dataset][sensitive_attributes[att][0]])\n",
    "        subgroup_scores[dataset][att]['right'] = np.array(db_fold[dataset][sensitive_attributes[att][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ed77b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine sims: {'facenet-webface': {'cal': array([0.61013806, 0.536733  , 0.6310155 , ..., 0.3443838 , 0.24821165,\n",
      "       0.24586767]), 'test': array([0.42275068, 0.39303565, 0.6094283 , ..., 0.40219867, 0.37166822,\n",
      "       0.06538376])}}\n",
      "\n",
      "Confidences: {'facenet-webface': {}}\n",
      "\n",
      "Ground truth: {'cal': array([ True,  True,  True, ..., False, False, False]), 'test': array([ True,  True,  True, ..., False, False, False])}\n",
      "\n",
      "Subgroup scores: {'cal': {'ethnicity': {'left': array(['African', 'African', 'African', ..., 'Indian', 'Indian', 'Indian'],\n",
      "      dtype=object), 'right': array(['African', 'African', 'African', ..., 'Indian', 'Indian', 'Indian'],\n",
      "      dtype=object)}}, 'test': {'ethnicity': {'left': array(['African', 'African', 'African', ..., 'Indian', 'Indian', 'Indian'],\n",
      "      dtype=object), 'right': array(['African', 'African', 'African', ..., 'Indian', 'Indian', 'Indian'],\n",
      "      dtype=object)}}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Cosine sims: {scores}\\n')\n",
    "print(f'Confidences: {confidences}\\n')\n",
    "print(f'Ground truth: {ground_truth}\\n')\n",
    "print(f'Subgroup scores: {subgroup_scores}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65c5b31",
   "metadata": {},
   "source": [
    "### Checking the size of the entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96734894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity: 21596 (cal), 2398 (test)\n",
      "Ground truth: 21596 (cal), 2398 (test)\n",
      "Subgroup scores: 21596 (left), 21596 (right)"
     ]
    }
   ],
   "source": [
    "print('Cosine similarity:', end = ' ')\n",
    "print(len(scores[feature]['cal']), end = ' (cal), ')\n",
    "print(len(scores[feature]['test']), end = ' (test)\\n')\n",
    "\n",
    "print('Ground truth:', end = ' ')\n",
    "print(len(ground_truth['cal']), end = ' (cal), ')\n",
    "print(len(ground_truth['test']), end = ' (test)\\n')\n",
    "\n",
    "print('Subgroup scores:', end = ' ')\n",
    "print(len(subgroup_scores['cal']['ethnicity']['left']), end = ' (left), ')\n",
    "print(len(subgroup_scores['cal']['ethnicity']['right']), end = ' (right)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e490f4fb",
   "metadata": {},
   "source": [
    "### Drop missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6c2ece33",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.isnan(scores[feature]['cal']) == False\n",
    "\n",
    "# If there are missing values, remove those data points\n",
    "if sum(indices) < len(indices):\n",
    "    scores[feature]['cal'] = scores[feature]['cal'][indices]\n",
    "    ground_truth['cal'] = ground_truth['cal'][indices]\n",
    "    subgroup_scores['cal']['ethnicity']['left'] = subgroup_scores['cal']['ethnicity']['left'][indices]\n",
    "    subgroup_scores['cal']['ethnicity']['right'] = subgroup_scores['cal']['ethnicity']['right'][indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b4398185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = np.isnan(scores[feature]['cal']) == True\n",
    "indices = np.isnan(ground_truth['cal']) == True\n",
    "\n",
    "sum(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14743b1",
   "metadata": {},
   "source": [
    "### Calculating confidence scores for baseline (based on beta calibration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "southwest-lexington",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[0;32m----> 2\u001b[0m     confidences[feature][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbaseline\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mbaseline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscores\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mground_truth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcalibration_method\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/FACT/faircal/code/approaches.py:29\u001b[0m, in \u001b[0;36mbaseline\u001b[0;34m(scores, ground_truth, nbins, calibration_method, score_min, score_max)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCalibration method \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m not available\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m calibration_method)\n\u001b[0;32m---> 29\u001b[0m confidences \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcal\u001b[39m\u001b[38;5;124m'\u001b[39m: calibration\u001b[38;5;241m.\u001b[39mpredict(scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcal\u001b[39m\u001b[38;5;124m'\u001b[39m]), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mcalibration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscores\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m}\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m confidences\n",
      "File \u001b[0;32m~/Documents/FACT/faircal/code/calibration_methods.py:168\u001b[0m, in \u001b[0;36mBetaCalibration.predict\u001b[0;34m(self, S)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmap_[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    166\u001b[0m     x \u001b[38;5;241m=\u001b[39m x[:, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m[:, \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/progLab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1372\u001b[0m, in \u001b[0;36mLogisticRegression.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1364\u001b[0m ovr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_class \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124movr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   1365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_class \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1366\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1369\u001b[0m     )\n\u001b[1;32m   1370\u001b[0m )\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ovr:\n\u001b[0;32m-> 1372\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_proba_lr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m     decision \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/progLab/lib/python3.9/site-packages/sklearn/linear_model/_base.py:435\u001b[0m, in \u001b[0;36mLinearClassifierMixin._predict_proba_lr\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_predict_proba_lr\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;124;03m\"\"\"Probability estimation for OvR logistic regression.\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \n\u001b[1;32m    431\u001b[0m \u001b[38;5;124;03m    Positive class probabilities are computed as\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;124;03m    1. / (1. + np.exp(-self.decision_function(X)));\u001b[39;00m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;124;03m    multiclass is handled by normalizing that over all classes.\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 435\u001b[0m     prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m     expit(prob, out\u001b[38;5;241m=\u001b[39mprob)\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m prob\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/progLab/lib/python3.9/site-packages/sklearn/linear_model/_base.py:401\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    398\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    399\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 401\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    402\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39mreshape(scores, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/progLab/lib/python3.9/site-packages/sklearn/base.py:535\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 535\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    536\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/progLab/lib/python3.9/site-packages/sklearn/utils/validation.py:919\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    913\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    914\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    915\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    916\u001b[0m         )\n\u001b[1;32m    918\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 919\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    927\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/progLab/lib/python3.9/site-packages/sklearn/utils/validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m     )\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "for feature in features:\n",
    "    confidences[feature]['baseline'] = baseline(scores[feature], ground_truth, nbins, calibration_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c087238d",
   "metadata": {},
   "source": [
    "### Calculating confidence scores for baseline (based on beta calibration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6a391ad2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[0;32m----> 2\u001b[0m     confidences[feature][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moracle\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43moracle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscores\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mground_truth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgroup_scores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcalibration_method\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/FACT/faircal/code/approaches.py:61\u001b[0m, in \u001b[0;36moracle\u001b[0;34m(scores, ground_truth, subgroup_scores, subgroups, nbins, calibration_method)\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCalibration method \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m not available\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m calibration_method)\n\u001b[1;32m     60\u001b[0m         confidences[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcal\u001b[39m\u001b[38;5;124m'\u001b[39m][att][select[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcal\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m calibration\u001b[38;5;241m.\u001b[39mpredict(scores_cal_subgroup)\n\u001b[0;32m---> 61\u001b[0m         confidences[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m][att][select[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[43mcalibration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscores\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m confidences\n",
      "File \u001b[0;32m~/Documents/FACT/faircal/code/calibration_methods.py:168\u001b[0m, in \u001b[0;36mBetaCalibration.predict\u001b[0;34m(self, S)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmap_[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    166\u001b[0m     x \u001b[38;5;241m=\u001b[39m x[:, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m[:, \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/progLab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1372\u001b[0m, in \u001b[0;36mLogisticRegression.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1364\u001b[0m ovr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_class \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124movr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   1365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_class \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1366\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1369\u001b[0m     )\n\u001b[1;32m   1370\u001b[0m )\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ovr:\n\u001b[0;32m-> 1372\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_proba_lr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m     decision \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/progLab/lib/python3.9/site-packages/sklearn/linear_model/_base.py:435\u001b[0m, in \u001b[0;36mLinearClassifierMixin._predict_proba_lr\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_predict_proba_lr\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;124;03m\"\"\"Probability estimation for OvR logistic regression.\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \n\u001b[1;32m    431\u001b[0m \u001b[38;5;124;03m    Positive class probabilities are computed as\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;124;03m    1. / (1. + np.exp(-self.decision_function(X)));\u001b[39;00m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;124;03m    multiclass is handled by normalizing that over all classes.\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 435\u001b[0m     prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m     expit(prob, out\u001b[38;5;241m=\u001b[39mprob)\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m prob\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/progLab/lib/python3.9/site-packages/sklearn/linear_model/_base.py:401\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    398\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    399\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 401\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    402\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39mreshape(scores, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/progLab/lib/python3.9/site-packages/sklearn/base.py:535\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 535\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    536\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/progLab/lib/python3.9/site-packages/sklearn/utils/validation.py:919\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    913\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    914\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    915\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    916\u001b[0m         )\n\u001b[1;32m    918\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 919\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    927\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/progLab/lib/python3.9/site-packages/sklearn/utils/validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m     )\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "for feature in features:\n",
    "    confidences[feature]['oracle'] = oracle(scores[feature], ground_truth, subgroup_scores, subgroups, nbins, calibration_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ddf1bb",
   "metadata": {},
   "source": [
    "### Loading the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ea2be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_data = pickle.load(open(f'embeddings/{feature}_{dataset_name}_embeddings.pk', 'rb'))\n",
    "\n",
    "if dataset_name == 'bfw':\n",
    "    embedding_data['img_path'] = embedding_data['img_path'].apply(lambda x: x.replace('data/bfw/bfw-cropped-aligned/', ''))\n",
    "if dataset_name == 'rfw':\n",
    "    embedding_data['img_path'] = embedding_data['img_path'].apply(lambda x: x.replace('data/rfw/data/', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fbbe32",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embedding_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3639a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(scores[feature]['cal']))\n",
    "print(len(ground_truth['cal']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab2ee51",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset_name)\n",
    "print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-conference",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in features:\n",
    "    _, _, confidences[feature]['faircal'], cluster_settings = cluster_methods(\n",
    "                nbins,\n",
    "                calibration_method,\n",
    "                dataset_name,\n",
    "                feature,\n",
    "                fold,\n",
    "                db_fold,\n",
    "                100,\n",
    "                False,\n",
    "                0,\n",
    "                embedding_data\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "judicial-compound",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in features:\n",
    "    _, _, confidences[feature]['fsn'], cluster_settings = cluster_methods(\n",
    "                nbins,\n",
    "                calibration_method,\n",
    "                dataset_name,\n",
    "                feature,\n",
    "                fold,\n",
    "                db_fold,\n",
    "                100,\n",
    "                True,\n",
    "                1e-3\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-matthew",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in features:\n",
    "    _, confidences[feature]['ftc'], _ = ftc(dataset_name, feature, db_fold, nbins, calibration_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "familiar-chapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in features:\n",
    "    _, confidences[feature]['agenda'], _, _, _ = agenda(dataset_name, feature, db_fold, nbins, calibration_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1e9cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confidences['facenet-webface'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-rolling",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_fold['test']['baseline'] = confidences['facenet-webface']['baseline']['test']\n",
    "db_fold['test']['oracle'] = confidences['facenet-webface']['oracle']['test']['ethnicity']\n",
    "# db_fold['test']['fsn'] = confidences['facenet-webface']['fsn']['test']\n",
    "# db_fold['test']['ftc'] = confidences['facenet-webface']['ftc']['test']\n",
    "# db_fold['test']['agenda'] = confidences['facenet-webface']['agenda']['test']\n",
    "# db_fold['test']['faircal'] = confidences['facenet-webface']['faircal']['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspected-worthy",
   "metadata": {},
   "outputs": [],
   "source": [
    "legend_fontsize = 18\n",
    "title_fontsize = 24\n",
    "label_fontsize = 20\n",
    "ticks_fontsize = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff62c983",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_fold['test']['pair'] = db_fold['test']['pair'].replace('Ungenuine', 'Imposter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impossible-citation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subgroups = ['African', 'Asian', 'Caucasian', 'Indian']\n",
    "# title_columns = ['Baseline', 'Baseline+Calibration', 'Oracle Calibration', 'FairCal (Ours)']\n",
    "title_columns = ['Baseline']\n",
    "# columns = ['facenet-webface','baseline','oracle', 'bmc']\n",
    "columns = ['facenet-webface','baseline','oracle']\n",
    "\n",
    "fig, axes = plt.subplots(1,len(columns),figsize=(20,5), sharey=True)\n",
    "\n",
    "# creating a dictionary with one specific color per group:\n",
    "my_pal = {\"Genuine\": \"royalblue\", \"Imposter\": \"skyblue\"}\n",
    "fpr_subgroup = {}\n",
    "for i_aux, aux in enumerate(columns):\n",
    "    sns.violinplot(\n",
    "    x ='ethnicity',\n",
    "    hue=\"pair\",\n",
    "    y=aux,\n",
    "    split=True,\n",
    "    data=db_fold['test'],\n",
    "    scale=\"count\",\n",
    "    inner=\"quartile\",\n",
    "    ax = axes[i_aux],\n",
    "    order=subgroups,\n",
    "    palette=my_pal\n",
    ")\n",
    "    axes[i_aux].legend(loc = 'lower right', fontsize=legend_fontsize)\n",
    "    axes[i_aux].set_xlabel('Ethnicity', fontsize=label_fontsize)\n",
    "    axes[i_aux].set_title(title_columns[i_aux], fontsize=title_fontsize)\n",
    "    if i_aux == 0:\n",
    "        axes[i_aux].set_ylabel('Cosine Similarity Score', fontsize=label_fontsize)\n",
    "    else:\n",
    "        axes[i_aux].set_ylabel('Probability', fontsize=label_fontsize)\n",
    "    labels = [item.get_text() for item in axes[i_aux].get_yticklabels()]\n",
    "    empty_string_labels = ['']*len(labels)\n",
    "    axes[i_aux].set_yticklabels(empty_string_labels)\n",
    "\n",
    "    axes[i_aux].tick_params(axis='x', labelsize=ticks_fontsize-2)\n",
    "\n",
    "    global_fpr,global_tpr,global_thr = sklearn.metrics.roc_curve(\n",
    "            y_true = ground_truth['test'],\n",
    "            y_score = db_fold['test'][aux],\n",
    "            drop_intermediate=False,\n",
    "            pos_label = True)\n",
    "    \n",
    "    axes[i_aux].axhline(global_thr[np.argmin(np.abs(global_fpr-0.05))],\n",
    "                    ls='-',\n",
    "                    linewidth=2,\n",
    "                    alpha = 1,\n",
    "                    c='black')\n",
    "    fpr_subgroup[aux] = {}\n",
    "    for j, subgroup in enumerate(subgroups):\n",
    "        select = subgroup_scores['test']['ethnicity']['left'] == subgroup\n",
    "        fpr,tpr,thr = sklearn.metrics.roc_curve(\n",
    "            y_true = ground_truth['test'][select],\n",
    "            y_score = db_fold['test'][aux][select],\n",
    "            drop_intermediate=False,\n",
    "            pos_label = True)\n",
    "        axes[i_aux].hlines(y = thr[np.argmin(np.abs(fpr-0.05))],\n",
    "                       ls='-',\n",
    "                       color='crimson',\n",
    "                       linewidth=3,\n",
    "                       xmin =j-0.5,\n",
    "                       xmax = j+1-0.5)\n",
    "        fpr_subgroup[aux][j] = 100*fpr[np.argmin(np.abs(thr-np.interp(0.05,global_fpr,global_thr)))]\n",
    "        print(\"%s - %s FPR = %1.3f\"%(title_columns[i_aux], subgroup, fpr_subgroup[aux][j]))\n",
    "fig.tight_layout()\n",
    "plt.savefig('figs_iclr/facenet-webface_score_distributions_fpr_thresholds.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-champion",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature = 'facenet-webface'\n",
    "metrics = {'aad': {}, 'mad': {}, 'std': {}}\n",
    "subgroups = ['African', 'Asian', 'Indian', 'Caucasian']\n",
    "title_columns = ['Baseline', 'AGENDA','FTC', 'FSN', 'FairCal (Ours)']\n",
    "columns = ['facenet-webface','agenda', 'ftc', 'fsn','bmc']\n",
    "fig, axes = plt.subplots(1,len(columns),figsize=(20,5), sharey=True)\n",
    "for i_aux,aux in enumerate(columns):\n",
    "    global_fpr,global_tpr,global_thr = sklearn.metrics.roc_curve(\n",
    "            y_true = ground_truth['test'],\n",
    "            y_score = db_fold['test'][aux],\n",
    "            drop_intermediate=False,\n",
    "            pos_label = True)\n",
    "    fpr_subgroup[aux] = np.zeros(len(subgroups))\n",
    "    for j, subgroup in enumerate(subgroups):\n",
    "        select = subgroup_scores['test']['ethnicity']['left'] == subgroup\n",
    "        fpr,tpr,thr = sklearn.metrics.roc_curve(\n",
    "            y_true = ground_truth['test'][select],\n",
    "            y_score = db_fold['test'][aux][select],\n",
    "            drop_intermediate=False,\n",
    "            pos_label = True)\n",
    "        axes[i_aux].plot(np.interp(thr,global_thr[::-1],global_fpr[::-1]),fpr, linewidth=2)\n",
    "        fpr_subgroup[aux][j] = 100*fpr[np.argmin(np.abs(thr-np.interp(0.05,global_fpr,global_thr)))]\n",
    "        print('%s %s - %1.1f'%(title_columns[i_aux],subgroup, fpr_subgroup[aux][j]))\n",
    "    metrics['aad'][aux] = np.mean(np.abs(fpr_subgroup[aux]-np.mean(fpr_subgroup[aux])))\n",
    "    metrics['mad'][aux] = np.max(np.abs(fpr_subgroup[aux]-np.mean(fpr_subgroup[aux])))\n",
    "    metrics['std'][aux] = np.std(fpr_subgroup[aux])\n",
    "    # print('AAD = %1.2f'%metrics['aad']['bmc'])\n",
    "    # print('MAD = %1.2f'%metrics['mad']['bmc'])\n",
    "    # print('STD = %1.2f'%metrics['std']['bmc'])\n",
    "    axes[i_aux].plot([0.05, 0.05],[0,1],'--k',linewidth=2)\n",
    "    axes[i_aux].legend(subgroups,loc = 'upper left')\n",
    "    axes[i_aux].set_xticks([0,0.02,0.04,0.06,0.08,0.1])\n",
    "    axes[i_aux].set_xlim(0,0.1)\n",
    "    axes[i_aux].set_ylim(0,0.18)\n",
    "    axes[i_aux].set_title(title_columns[i_aux], fontsize=title_fontsize)\n",
    "    axes[i_aux].set_xlabel('Global FPR', fontsize=title_fontsize)\n",
    "    if i_aux == 0:\n",
    "        axes[i_aux].set_ylabel('False Positive Rate', fontsize=title_fontsize)\n",
    "    axes[i_aux].tick_params(axis='both', which='major', labelsize=ticks_fontsize)\n",
    "fig.tight_layout()\n",
    "plt.savefig('figs_iclr/facenet-webface_thr_vs_fpr.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powerful-focus",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-suffering",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-duplicate",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "38bfd7062c2e40c254718556666e4422f04be01044787720715af94b520c2c5e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
